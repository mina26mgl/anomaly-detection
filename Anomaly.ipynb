{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b30374f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\IMENE\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cdist\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import networkx as nx\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import log_loss\n",
    "import category_encoders as ce\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import networkx as nx\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import silhouette_score\n",
    "from scipy.stats import gaussian_kde\n",
    "# from tensorflow.keras.callbacks import EarlyStopping\n",
    "import numpy as np\n",
    "# from scipy.stats import zscore\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score, precision_score, recall_score, log_loss\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "# from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from umap import UMAP\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from scipy.stats import entropy\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.manifold import TSNE\n",
    "from category_encoders import TargetEncoder\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.decomposition import PCA\n",
    "from tqdm import tqdm\n",
    "from category_encoders import TargetEncoder\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "import category_encoders as ce\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "import category_encoders as ce\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.cluster import KMeans\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.feature_extraction import FeatureHasher\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from scipy.sparse import hstack, csr_matrix\n",
    "from category_encoders import CountEncoder\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from scipy import sparse\n",
    "from scipy.optimize import minimize\n",
    "# from keras.callbacks import ReduceLROnPlateau\n",
    "# from sklearn.ensemble import VotingAnomalyDetector\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay, roc_auc_score\n",
    "import networkx as nx\n",
    "from networkx.algorithms import community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "727a2a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"DATA.csv\", sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00238186",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_unsupervised(df):\n",
    "    df = df.copy()\n",
    "\n",
    "    all_ordinal_cols = ['full_date', 'lib_jour', 'lib_mois', 'Birth_date', 'Activation_Date',\n",
    "                        'First_Call_Date', 'Last_Call_Date', 'status_date', 'Document_Validation_Date',\n",
    "                        'DOC_SCN_DT']\n",
    "    ordinal_cols = [col for col in all_ordinal_cols if col in df.columns]\n",
    "    num_cols = df.select_dtypes(include=np.number).columns.tolist()\n",
    "    cat_cols = df.select_dtypes(include='object').columns.tolist()\n",
    "    counter_cols = [col for col in cat_cols if col not in ordinal_cols]\n",
    "\n",
    "    # Numérique\n",
    "    num_pipe = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='mean')),\n",
    "        ('scaler', StandardScaler())\n",
    "    ])\n",
    "    df_num = pd.DataFrame(num_pipe.fit_transform(df[num_cols]), columns=num_cols, index=df.index).astype(np.float32)\n",
    "\n",
    "    # Ordinal\n",
    "    if ordinal_cols:\n",
    "        ordinal_pipe = Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "            ('encoder', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1))\n",
    "        ])\n",
    "        df_ord = pd.DataFrame(ordinal_pipe.fit_transform(df[ordinal_cols]), columns=ordinal_cols, index=df.index).astype(np.float32)\n",
    "    else:\n",
    "        df_ord = pd.DataFrame(index=df.index)\n",
    "\n",
    "    # Count\n",
    "    if counter_cols:\n",
    "        count_pipe = Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "            ('encoder', ce.CountEncoder())\n",
    "        ])\n",
    "        df_count = pd.DataFrame(count_pipe.fit_transform(df[counter_cols]), columns=counter_cols, index=df.index)\n",
    "        df_count = np.log1p(df_count).astype(np.float32)  # sécurisation\n",
    "    else:\n",
    "        df_count = pd.DataFrame(index=df.index)\n",
    "\n",
    "    df_processed = pd.concat([df_num, df_ord, df_count], axis=1)\n",
    "\n",
    "    # Nettoyage final\n",
    "    df_processed.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    df_processed.fillna(0, inplace=True)\n",
    "\n",
    "    return df_processed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5fb0a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cust_id               int64\n",
       "nin                  object\n",
       "ICC                  object\n",
       "ID_doc               object\n",
       "pdv_sk                int64\n",
       "                     ...   \n",
       "minor_ok            float64\n",
       "cn_valid            float64\n",
       "ocr_violation         int64\n",
       "Id_operation          int64\n",
       "type_d_opeartion     object\n",
       "Length: 74, dtype: object"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.read_csv(\"DATA2.csv\", sep=';', encoding='latin1')\n",
    "\n",
    "\n",
    "types = df2.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b5e98cd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   column          dtype\n",
      "                      nin         object\n",
      "                   status         object\n",
      "              status_date         object\n",
      "               Birth_date         object\n",
      "                  age_sub          int64\n",
      "                   Gender         object\n",
      "                  id_type         object\n",
      "        subscription_type        float32\n",
      "           tarrif_profile         object\n",
      "                 type_sim         object\n",
      "          Activation_Date         object\n",
      "          First_Call_Date         object\n",
      "           Last_Call_Date         object\n",
      "                   ID_doc        float32\n",
      "   Document_Validation_2G         object\n",
      "   Document_Validation_3G         object\n",
      "   Document_Validation_4G         object\n",
      "         Document_stamped         object\n",
      "   document_scaned_status         object\n",
      " Document_Validation_Date         object\n",
      "               DOC_SCN_DT         object\n",
      "                   pdv_sk          int64\n",
      "                   PoS_ID         object\n",
      "              DOC_VAL_USR         object\n",
      "              DOK_SCN_USR        float32\n",
      "                       BU        float32\n",
      "          localisation_sk          int64\n",
      "                Postal_ID          int64\n",
      "                 Province        float32\n",
      "                     City         object\n",
      "                   Street         object\n",
      "                  id_date          int64\n",
      "                full_date datetime64[ns]\n",
      "                     year          int64\n",
      "                     mois          int64\n",
      "                 lib_mois        float32\n",
      "                    jours          int64\n",
      "                 lib_jour         object\n",
      "                   NIN_ok          int64\n",
      "                   DOB_ok          int64\n",
      "                 minor_ok          int64\n",
      "                 cn_valid        float32\n",
      "         similarity_score          int64\n",
      "            ocr_violation          int64\n",
      "             id_operation          int64\n",
      "         type_d_operation        float32\n",
      "     similarity_score_bin          int64\n",
      "         violation_reason         object\n",
      "        temps_moyen_appel        float64\n",
      "   temps_moyen_traitement        float64\n",
      "        reactivite_client        float64\n",
      "    Revenue_Last_2_Months        float64\n",
      "   Revenue_Last_12_Months        float64\n",
      "       ARPU_Last_2_Months        float64\n",
      "            segment_value         object\n",
      "      client_haut_revenue          int64\n",
      "doc_scan_avant_activation        float32\n",
      "          score_confiance          int64\n"
     ]
    }
   ],
   "source": [
    "# Donne un DataFrame avec nom + type\n",
    "df_types = pd.DataFrame(df.dtypes, columns=['dtype']).reset_index()\n",
    "df_types.columns = ['column', 'dtype']\n",
    "print(df_types.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad1ea36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- Isolation Forest Modifié pour Silhouette Score -----\n",
    "class IsolationTree:\n",
    "    def __init__(self, max_depth):\n",
    "        self.max_depth = max_depth\n",
    "        self.tree = None\n",
    "    @staticmethod\n",
    "    def _c(n):\n",
    "        if n <= 1: \n",
    "            return 0\n",
    "        return 2 * (np.log(n - 1) + 0.5772) - (2 * (n - 1) / n)\n",
    "    def fit(self, X, depth=0):\n",
    "        if depth >= self.max_depth or len(X) <= 1:\n",
    "            return {\"size\": len(X)}\n",
    "        n_features = X.shape[1]\n",
    "        feature = np.random.randint(0, n_features)\n",
    "        min_val, max_val = np.min(X.iloc[:, feature]), np.max(X.iloc[:, feature])\n",
    "        if min_val == max_val:\n",
    "            return {\"size\": len(X)}\n",
    "        split = np.random.uniform(min_val, max_val)\n",
    "        left = X[X.iloc[:, feature] < split]\n",
    "        right = X[X.iloc[:, feature] >= split]\n",
    "\n",
    "        return {\n",
    "            \"feature\": feature,\n",
    "            \"split\": split,\n",
    "            \"left\": self.fit(left, depth + 1),\n",
    "            \"right\": self.fit(right, depth + 1)\n",
    "        }\n",
    "    \n",
    "    def path_length(self, x, node=None, depth=0):\n",
    "        if node is None:\n",
    "            node = self.tree\n",
    "        if \"size\" in node:\n",
    "            return depth + self._c(node[\"size\"])\n",
    "        \n",
    "        # Make sure we don't try to access non-existent features\n",
    "        if node[\"feature\"] >= len(x):\n",
    "            return depth + self._c(1)  # Return a base case if feature is out of bounds\n",
    "            \n",
    "        value = x[node[\"feature\"]]\n",
    "\n",
    "        if value < node[\"split\"]:\n",
    "            return self.path_length(x, node[\"left\"], depth + 1)\n",
    "        else:\n",
    "            return self.path_length(x, node[\"right\"], depth + 1)\n",
    "    \n",
    "\n",
    "class IsolationForestScratch:\n",
    "    def __init__(self, n_trees=100, max_depth=None):\n",
    "        self.n_trees = n_trees\n",
    "        self.max_depth = max_depth\n",
    "        self.trees = []\n",
    "        self.X = None\n",
    "        self.threshold = None\n",
    "        self.scores = None\n",
    "        self.contamination = 0.05  # Default contamination rate\n",
    "    \n",
    "\n",
    "    def anomaly_score(self, X=None):\n",
    "        X = self.X if X is None else (X.values if isinstance(X, pd.DataFrame) else X)\n",
    "        scores = []\n",
    "        \n",
    "        for i in range(len(X)):\n",
    "            x = X[i]\n",
    "            if isinstance(x, pd.Series):  # Convert Series to numpy array if needed\n",
    "                x = x.values\n",
    "                \n",
    "            lengths = [t.path_length(x) for t in self.trees]\n",
    "            avg = np.mean(lengths)\n",
    "            score = 2 ** (-avg / IsolationTree._c(len(self.X)))  # Call through IsolationTree\n",
    "            scores.append(score)\n",
    "        return np.array(scores)\n",
    "    def fit(self, X):\n",
    "        # Convert to numpy array and ensure 2D\n",
    "        self.X = np.asarray(X)\n",
    "        if len(self.X.shape) == 1:\n",
    "            self.X = self.X.reshape(-1, 1)\n",
    "            \n",
    "        height_limit = int(np.ceil(np.log2(len(self.X))))\n",
    "        self.trees = []\n",
    "        \n",
    "        for _ in range(self.n_trees):\n",
    "            sample_idx = np.random.choice(len(self.X), len(self.X) // 2, replace=False)\n",
    "            sample = self.X[sample_idx]  # Use numpy array directly\n",
    "            tree = IsolationTree(self.max_depth or height_limit)\n",
    "            tree.tree = tree.fit(pd.DataFrame(sample))  # Convert to DataFrame only for the tree fitting\n",
    "            self.trees.append(tree)\n",
    "        \n",
    "        # Calculate threshold based on contamination\n",
    "        scores = self.anomaly_score()\n",
    "        self.threshold = np.percentile(scores, 100 * (1 - self.contamination))\n",
    "    \n",
    "    def get_distance_matrix(self):\n",
    "        \"\"\"Retourne une matrice de distance basée sur les scores d'anomalie\"\"\"\n",
    "        scores = self.anomaly_score()\n",
    "        return cdist(scores.reshape(-1, 1), scores.reshape(-1, 1))\n",
    "    \n",
    "    def get_cluster_labels(self, X, threshold=None):\n",
    "        \"\"\"\n",
    "        Returns cluster labels (0=normal, 1=anomaly) based on anomaly scores\n",
    "        If no threshold is provided, uses the one calculated during fit()\n",
    "        \"\"\"\n",
    "        scores = self.anomaly_score(X)\n",
    "        threshold = threshold or self.threshold\n",
    "        \n",
    "        if threshold is None:\n",
    "            raise ValueError(\"Threshold not set. Call fit() first or provide a threshold.\")\n",
    "            \n",
    "        return (scores > threshold).astype(int)\n",
    "\n",
    "\n",
    "# ----- LOF Modifié pour Silhouette Score -----\n",
    "class LOF:\n",
    "    def __init__(self, k=10):\n",
    "        self.k = k\n",
    "        self.X = None\n",
    "        self.distances = None\n",
    "        self.threshold = 1.5 \n",
    "\n",
    "    def fit(self, X, contamination=0.05):\n",
    "        self.X = X.values if isinstance(X, pd.DataFrame) else X\n",
    "        self.distances = cdist(self.X, self.X)\n",
    "        \n",
    "        # Calculate threshold based on contamination\n",
    "        scores = self.anomaly_score()\n",
    "        self.threshold = np.percentile(scores, 100 * (1 - contamination))\n",
    "\n",
    "    def _reach_dist(self, i, j):\n",
    "        dist = self.distances[i, j]\n",
    "        k_dist_j = np.partition(self.distances[j], self.k)[self.k]\n",
    "        return max(dist, k_dist_j)\n",
    "\n",
    "    def _lrd(self, i):\n",
    "        neighbors = np.argsort(self.distances[i])[1:self.k+1]\n",
    "        reach_dists = [self._reach_dist(i, j) for j in neighbors]\n",
    "        return 1 / (np.mean(reach_dists) + 1e-10)\n",
    "\n",
    "    def anomaly_score(self, X=None):\n",
    "        if X is None:\n",
    "            X = self.X\n",
    "        else:\n",
    "            X = X.values if isinstance(X, pd.DataFrame) else X\n",
    "            distances = cdist(X, self.X)\n",
    "        \n",
    "        lrd_scores_train = [self._lrd(i) for i in range(len(self.X))]\n",
    "        scores = []\n",
    "        \n",
    "        for i in range(len(X)):\n",
    "            if X is self.X:\n",
    "                neighbors = np.argsort(self.distances[i])[1:self.k+1]\n",
    "            else:\n",
    "                neighbors = np.argsort(distances[i])[:self.k]\n",
    "            \n",
    "            lrd_x = 1 / (np.mean([\n",
    "                max(distances[i][j] if X is not self.X else self.distances[i][j], \n",
    "                np.partition(self.distances[j], self.k)[self.k])\n",
    "                for j in neighbors\n",
    "            ]) + 1e-10)\n",
    "            \n",
    "            ratios = [lrd_scores_train[j] / lrd_x for j in neighbors]\n",
    "            scores.append(np.mean(ratios))\n",
    "        \n",
    "        return np.array(scores)\n",
    "        \n",
    "    \n",
    "    def get_distance_matrix(self):\n",
    "        \"\"\"Retourne la matrice de distance originale\"\"\"\n",
    "        return self.distances\n",
    "    \n",
    "    def get_cluster_labels(self, X, threshold=None):\n",
    "        \"\"\"Return labels for input data X\"\"\"\n",
    "        scores = self.anomaly_score(X)\n",
    "        threshold = threshold or self.threshold\n",
    "        return (scores > threshold).astype(int)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ----- One-Class SVM Simplifié -----\n",
    "class OneClassSVM_RBF:\n",
    "    def __init__(self, gamma=0.1):\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def fit(self, X):\n",
    "        self.X_train = X\n",
    "        self.kernel = self._rbf_kernel(X, X)\n",
    "\n",
    "    def _rbf_kernel(self, X1, X2):\n",
    "        sq_dists = cdist(X1, X2, 'sqeuclidean')\n",
    "        return np.exp(-self.gamma * sq_dists)\n",
    "\n",
    "    def decision_function(self, X):\n",
    "        K = self._rbf_kernel(X, self.X_train)\n",
    "        return np.mean(K, axis=1)\n",
    "\n",
    "    def anomaly_score(self, X):\n",
    "        return -self.decision_function(X)\n",
    "\n",
    "#------Autoencoder------\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, input_dim, latent_dim=10):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, latent_dim)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, input_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.encoder(x)\n",
    "        return self.decoder(z), z\n",
    "\n",
    "    \n",
    "    def fit(self, X):\n",
    "        # === 1. Vérification et conversion des données ===\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X.values.astype(np.float32)\n",
    "        elif not isinstance(X, np.ndarray):\n",
    "            raise ValueError(\"Input must be DataFrame or numpy array\")\n",
    "        \n",
    "        # === 2. Initialisation du modèle ===\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.to(device)\n",
    "        \n",
    "        X_tensor = torch.FloatTensor(X).to(device)\n",
    "        dataset = TensorDataset(X_tensor)\n",
    "        loader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "        \n",
    "        criterion = nn.MSELoss()\n",
    "        optimizer = optim.Adam(self.parameters(), lr=1e-3)\n",
    "        \n",
    "        # === 3. Entraînement ===\n",
    "        self.train()\n",
    "        for epoch in range(30):\n",
    "            epoch_loss = 0\n",
    "            for batch in loader:\n",
    "                x_batch = batch[0]\n",
    "                optimizer.zero_grad()\n",
    "                x_recon, _ = self(x_batch)\n",
    "                loss = criterion(x_recon, x_batch)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                epoch_loss += loss.item()\n",
    "            \n",
    "            if epoch % 10 == 0:\n",
    "                avg_loss = epoch_loss / len(loader)\n",
    "                print(f\"Epoch {epoch} - Loss: {avg_loss:.4f}\")\n",
    "        \n",
    "        # === 4. Encodage dans l'espace latent ===\n",
    "        with torch.no_grad():\n",
    "            self.eval()\n",
    "            _, latent = self(X_tensor)\n",
    "            latent_np = latent.cpu().numpy()\n",
    "        \n",
    "        # === 5. Clustering ===\n",
    "        kmeans = KMeans(n_clusters=2, random_state=42)\n",
    "        y_pred = kmeans.fit_predict(latent_np)\n",
    "        print(f\" Kmeans Silhouette Score: {silhouette_score(latent_np, y_pred):.3f}\")\n",
    "        # LOF\n",
    "        lof = LOF(k=20)\n",
    "        lof.fit(latent_np)\n",
    "        lof_scores = lof.anomaly_score()\n",
    "        lof_labels = lof.get_cluster_labels(pd.DataFrame(latent_np))\n",
    "        print(f\"LOF Silhouette Score: {silhouette_score(lof.get_distance_matrix(), lof_labels, metric='precomputed'):.3f}\")\n",
    "        \n",
    "        # Isolation Forest\n",
    "        iso_forest = IsolationForestScratch(n_trees=100)\n",
    "        iso_forest.fit(pd.DataFrame(latent_np))\n",
    "        iso_scores = iso_forest.anomaly_score(pd.DataFrame(latent_np))\n",
    "        iso_labels = iso_forest.get_cluster_labels(pd.DataFrame(latent_np))\n",
    "        print(f\"Isolation Forest Silhouette Score: {silhouette_score(iso_forest.get_distance_matrix(), iso_labels, metric='precomputed'):.3f}\")\n",
    "        self.latent_np = latent_np\n",
    "        self.lof = lof\n",
    "        self.iforest = iso_forest\n",
    "        self.lof_labels = lof_labels\n",
    "        self.iso_labels = iso_labels\n",
    "        return {\n",
    "            'latent': pd.DataFrame(latent_np),\n",
    "            'cluster_labels': y_pred,\n",
    "            'lof_scores': lof_scores,\n",
    "            'iso_scores': iso_scores,\n",
    "            'iso_labels': iso_labels,\n",
    "            'lof_labels': lof_labels\n",
    "        }\n",
    "    def encode(self, X):\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X.values.astype(np.float32)\n",
    "        elif not isinstance(X, np.ndarray):\n",
    "            raise ValueError(\"Input must be DataFrame or numpy array\")\n",
    "\n",
    "        self.eval()\n",
    "        device = next(self.parameters()).device\n",
    "\n",
    "        with torch.no_grad():\n",
    "            X_tensor = torch.FloatTensor(X).to(device)\n",
    "            latent = self.encoder(X_tensor)\n",
    "            return latent.cpu().numpy()\n",
    "\n",
    "    def reconstruct(self, X):\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X.values.astype(np.float32)\n",
    "\n",
    "        self.eval()\n",
    "        device = next(self.parameters()).device\n",
    "        with torch.no_grad():\n",
    "            X_tensor = torch.FloatTensor(X).to(device)\n",
    "            X_recon = self.decoder(self.encoder(X_tensor))\n",
    "            return X_recon.cpu().numpy()\n",
    "\n",
    "#--------META MODELE------\n",
    "class BayesianOrdinalEncoder:\n",
    "    def __init__(self, cols):\n",
    "        self.cols = cols\n",
    "        self.encoder = None\n",
    "\n",
    "    def fit_transform(self, X, y):\n",
    "        X_ = X.copy()\n",
    "        self.encoder = ce.LeaveOneOutEncoder(cols=self.cols, random_state=42, sigma=0.1)\n",
    "        return self.encoder.fit_transform(X_, y)\n",
    "\n",
    "    def transform(self, X):\n",
    "        X_ = X.copy()\n",
    "        return self.encoder.transform(X_)\n",
    "class ShrinkageBoostingClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, n_estimators=100, learning_rate=0.1, max_depth=5, stack_model=None, fast_mode=True):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.learning_rate = learning_rate\n",
    "        self.max_depth = max_depth\n",
    "        self.trees = []\n",
    "        self.tree_weights = []\n",
    "        self.scaler = StandardScaler()\n",
    "        self.encoder = None\n",
    "        \n",
    "        self.fast_mode = fast_mode\n",
    "        \n",
    "        if stack_model is None:\n",
    "            from sklearn.ensemble import RandomForestClassifier\n",
    "            self.stack_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "        else:\n",
    "            self.stack_model = stack_model\n",
    "\n",
    "    def _preprocess(self, X):\n",
    "        X = X.copy()\n",
    "        for col in X.columns:\n",
    "            col_str = str(col)\n",
    "            if 'date' in col_str.lower():\n",
    "                try:\n",
    "                    X[col] = pd.to_datetime(X[col], errors='coerce').astype('int64') // 10**9\n",
    "                except Exception:\n",
    "                    pass\n",
    "        \n",
    "        for col in X.columns:\n",
    "            if X[col].dtype == 'object':\n",
    "                X[col] = X[col].fillna('missing')\n",
    "            else:\n",
    "                X[col] = X[col].fillna(X[col].median())\n",
    "        return X\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X = pd.DataFrame(X).reset_index(drop=True)\n",
    "        y = pd.Series(y).reset_index(drop=True)\n",
    "\n",
    "        cat_cols = X.select_dtypes(include='object').columns.tolist()\n",
    "        if cat_cols:\n",
    "            self.encoder = BayesianOrdinalEncoder(cols=cat_cols)\n",
    "            X = self.encoder.fit_transform(X, y)\n",
    "\n",
    "        self.feature_names_ = X.columns.tolist()\n",
    "\n",
    "        X = pd.DataFrame(self.scaler.fit_transform(X), columns=X.columns)\n",
    "\n",
    "        F = np.zeros(len(y))\n",
    "        self.trees = []\n",
    "        self.tree_weights = []\n",
    "\n",
    "        for i in range(self.n_estimators):\n",
    "            p = 1 / (1 + np.exp(-F))\n",
    "            grad = y - p\n",
    "            tree = DecisionTreeRegressor(max_depth=self.max_depth)\n",
    "            tree.fit(X, grad)\n",
    "\n",
    "            pred = tree.predict(X)\n",
    "            delta = self.learning_rate * pred\n",
    "            F += delta\n",
    "\n",
    "            ll = log_loss(y, 1 / (1 + np.exp(-F)))\n",
    "            weight = 1 / (ll + 1e-5)\n",
    "            self.trees.append(tree)\n",
    "            self.tree_weights.append(weight)\n",
    "\n",
    "        stacked_preds = self._get_tree_outputs(X)\n",
    "        if self.stack_model is None:\n",
    "            from catboost import CatBoostClassifier\n",
    "            self.stack_model = CatBoostClassifier(\n",
    "                iterations=50,\n",
    "                learning_rate=0.1,\n",
    "                depth=4,\n",
    "                verbose=0,\n",
    "                random_seed=42,\n",
    "                task_type='GPU' if self.fast_mode else 'CPU'\n",
    "            )\n",
    "        # Fit le stack model une seule fois\n",
    "        self.stack_model.fit(stacked_preds, y)\n",
    "\n",
    "        # Calibration des probabilités : \"cv='prefit'\" car CatBoost est déjà entraîné\n",
    "        # self.stack_model = CalibratedClassifierCV(self.stack_model, method=\"sigmoid\", cv=\"prefit\")\n",
    "\n",
    "        # # Fit du calibrateur uniquement (pas le modèle CatBoost)\n",
    "        # self.stack_model.fit(stacked_preds, y)\n",
    "\n",
    "    def _get_tree_outputs(self, X):\n",
    "        outputs = [tree.predict(X) * w for tree, w in zip(self.trees, self.tree_weights)]\n",
    "        return np.vstack(outputs).T\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        X = pd.DataFrame(X).reset_index(drop=True)\n",
    "        X = self._preprocess(X)\n",
    "        if self.encoder:\n",
    "            X = self.encoder.transform(X)\n",
    "\n",
    "        X = pd.DataFrame(self.scaler.transform(X), columns=self.feature_names_)\n",
    "        stacked_preds = self._get_tree_outputs(X)\n",
    "        return self.stack_model.predict_proba(stacked_preds)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.argmax(self.predict_proba(X), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8675870c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnomalyDetector:\n",
    "    def __init__(self, autoencoder, contamination=0.05, features=None):\n",
    "        \"\"\"\n",
    "        autoencoder: module PyTorch avec fit, encode, predict\n",
    "        meta_model: modèle scikit-learn compatible (fit, predict, predict_proba)\n",
    "        contamination: pour seuil des erreurs de reconstruction\n",
    "        features: liste des colonnes à utiliser (subset de X.columns)\n",
    "        \"\"\"\n",
    "        self.autoencoder = autoencoder\n",
    "        self.meta_model = ShrinkageBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=5, stack_model=None, fast_mode=True)\n",
    "        self.contamination = contamination\n",
    "        self.features = features\n",
    "        self.fit_outputs = None\n",
    "    def fit(self, X):\n",
    "        if self.features:\n",
    "            X = X[self.features]\n",
    "\n",
    "        self.fit_outputs = self.autoencoder.fit(X)\n",
    "        \n",
    "        lof_labels = self.autoencoder.lof_labels\n",
    "        iso_labels = self.autoencoder.iso_labels\n",
    "\n",
    "        X_np = X.values.astype(np.float32) if isinstance(X, pd.DataFrame) else X\n",
    "        recon = self.autoencoder.reconstruct(X_np)\n",
    "\n",
    "        ae_errors = np.mean((X_np - recon) ** 2, axis=1)\n",
    "        ae_thresh = np.percentile(ae_errors, 100 * (1 - self.contamination))\n",
    "        ae_labels = (ae_errors > ae_thresh).astype(int)\n",
    "\n",
    "        df_meta = pd.DataFrame({\n",
    "            \"ae_label\": ae_labels,\n",
    "            \"lof_label\": lof_labels,\n",
    "            \"iso_label\": iso_labels\n",
    "        })\n",
    "\n",
    "        df_meta[\"meta_label\"] = (df_meta[[\"ae_label\", \"lof_label\", \"iso_label\"]].sum(axis=1) >= 2).astype(int)\n",
    "\n",
    "        self.meta_model.fit(df_meta[[\"ae_label\", \"lof_label\", \"iso_label\"]], df_meta[\"meta_label\"])\n",
    "\n",
    "    def predict(self, X):\n",
    "        if self.features:\n",
    "            X = X[self.features]\n",
    "\n",
    "        X_np = X.values.astype(np.float32) if isinstance(X, pd.DataFrame) else X\n",
    "        recon = self.autoencoder.reconstruct(X_np)\n",
    "\n",
    "        ae_errors = np.mean((X_np - recon) ** 2, axis=1)\n",
    "        ae_thresh = np.percentile(ae_errors, 100 * (1 - self.contamination))\n",
    "        ae_labels = (ae_errors > ae_thresh).astype(int)\n",
    "\n",
    "        latent = self.autoencoder.encode(X_np)\n",
    "        lof_labels = self.autoencoder.lof.get_cluster_labels(pd.DataFrame(latent))\n",
    "        iso_labels = self.autoencoder.iforest.get_cluster_labels(pd.DataFrame(latent))\n",
    "\n",
    "        df_pred = pd.DataFrame({\n",
    "            \"ae_label\": ae_labels,\n",
    "            \"lof_label\": lof_labels,\n",
    "            \"iso_label\": iso_labels\n",
    "        })\n",
    "\n",
    "        return self.meta_model.predict(df_pred)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        if self.features:\n",
    "            X = X[self.features]\n",
    "\n",
    "        X_np = X.values.astype(np.float32) if isinstance(X, pd.DataFrame) else X\n",
    "        recon = self.autoencoder.reconstruct(X_np)\n",
    "\n",
    "        ae_errors = np.mean((X_np - recon) ** 2, axis=1)\n",
    "        ae_thresh = np.percentile(ae_errors, 100 * (1 - self.contamination))\n",
    "        ae_labels = (ae_errors > ae_thresh).astype(int)\n",
    "\n",
    "        latent = self.autoencoder.encode(X_np)\n",
    "        lof_labels = self.autoencoder.lof.get_cluster_labels(pd.DataFrame(latent))\n",
    "        iso_labels = self.autoencoder.iforest.get_cluster_labels(pd.DataFrame(latent))\n",
    "\n",
    "        df_pred = pd.DataFrame({\n",
    "            \"ae_label\": ae_labels,\n",
    "            \"lof_label\": lof_labels,\n",
    "            \"iso_label\": iso_labels\n",
    "        })\n",
    "\n",
    "        return self.meta_model.predict_proba(df_pred)\n",
    "    def evaluate_unsupervised(self, X):\n",
    "        \"\"\"\n",
    "        Évalue le métamodèle sans labels, à l'aide de critères non supervisés.\n",
    "        Affiche :\n",
    "        - Score silhouette (séparation des classes dans l'espace latent)\n",
    "        - Taux de désaccord avec les prédicteurs de base\n",
    "        - Répartition des prédictions\n",
    "        - Erreur de reconstruction moyenne par classe\n",
    "        \"\"\"\n",
    "\n",
    "        if self.features:\n",
    "            X = X[self.features]\n",
    "\n",
    "        X_np = X.values.astype(np.float32) if isinstance(X, pd.DataFrame) else X\n",
    "        recon = self.autoencoder.reconstruct(X_np)\n",
    "        ae_errors = np.mean((X_np - recon) ** 2, axis=1)\n",
    "        ae_thresh = np.percentile(ae_errors, 100 * (1 - self.contamination))\n",
    "        ae_labels = (ae_errors > ae_thresh).astype(int)\n",
    "\n",
    "        latent = self.autoencoder.encode(X_np)\n",
    "        lof_labels = self.autoencoder.lof.get_cluster_labels(pd.DataFrame(latent))\n",
    "        iso_labels = self.autoencoder.iforest.get_cluster_labels(pd.DataFrame(latent))\n",
    "\n",
    "        df_meta = pd.DataFrame({\n",
    "            \"ae_label\": ae_labels,\n",
    "            \"lof_label\": lof_labels,\n",
    "            \"iso_label\": iso_labels,\n",
    "            \"recon_error\": ae_errors\n",
    "        })\n",
    "\n",
    "        df_meta[\"meta_pred\"] = self.meta_model.predict(df_meta[[\"ae_label\", \"lof_label\", \"iso_label\"]])\n",
    "\n",
    "        # Score de silhouette sur l’espace latent\n",
    "        try:\n",
    "            sil_score = silhouette_score(latent, df_meta[\"meta_pred\"])\n",
    "            print(f\"Silhouette score (latents, selon prédiction métamodèle) : {sil_score:.4f}\")\n",
    "        except Exception as e:\n",
    "            print(\"Silhouette score non calculé :\", str(e))\n",
    "\n",
    "        # Taux moyen de désaccord entre les modèles de base et le métamodèle\n",
    "        df_meta[\"disagreement\"] = (\n",
    "            (df_meta[\"meta_pred\"] != df_meta[\"ae_label\"]).astype(int) +\n",
    "            (df_meta[\"meta_pred\"] != df_meta[\"lof_label\"]).astype(int) +\n",
    "            (df_meta[\"meta_pred\"] != df_meta[\"iso_label\"]).astype(int)\n",
    "        )\n",
    "        mean_disagreement = df_meta[\"disagreement\"].mean()\n",
    "        print(f\"Taux moyen de désaccord (0 à 3) avec les modèles de base : {mean_disagreement:.4f}\")\n",
    "\n",
    "      \n",
    "\n",
    "        # Erreurs de reconstruction par classe prédite\n",
    "        print(\"\\nStatistiques d'erreur de reconstruction selon la classe prédite :\")\n",
    "        print(df_meta.groupby(\"meta_pred\")[\"recon_error\"].describe())\n",
    "\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7034225",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnomalyExplainer:\n",
    "    def __init__(self, features, preprocessor=None):\n",
    "        self.features = features\n",
    "        self.stats_ = {}\n",
    "        self.preprocessor = preprocessor\n",
    "        self.original_X_train = None  # nouvelle variable\n",
    "\n",
    "    def fit(self, X_train_original):\n",
    "        \"\"\"\n",
    "        Calcule les stats de référence sur les données normales non encodées.\n",
    "        \"\"\"\n",
    "        self.original_X_train = X_train_original[self.features].copy()\n",
    "\n",
    "        for col in self.features:\n",
    "            if np.issubdtype(self.original_X_train[col].dtype, np.number):\n",
    "                q1 = self.original_X_train[col].quantile(0.25)\n",
    "                q3 = self.original_X_train[col].quantile(0.75)\n",
    "                iqr = q3 - q1\n",
    "                median = self.original_X_train[col].median()\n",
    "                self.stats_[col] = {\n",
    "                    \"type\": \"numeric\",\n",
    "                    \"median\": median,\n",
    "                    \"iqr\": iqr,\n",
    "                    \"q1\": q1,\n",
    "                    \"q3\": q3\n",
    "                }\n",
    "            else:\n",
    "                top_val = self.original_X_train[col].mode()[0]\n",
    "                freq = self.original_X_train[col].value_counts(normalize=True).get(top_val, 0)\n",
    "                self.stats_[col] = {\n",
    "                    \"type\": \"categorical\",\n",
    "                    \"top_value\": top_val,\n",
    "                    \"frequency\": freq\n",
    "                }\n",
    "\n",
    "    def explain(self, X_anomalies_encoded, X_anomalies_original, top_k=3):\n",
    "        \"\"\"\n",
    "        Donne une explication avec les valeurs réelles, même si les données sont encodées.\n",
    "        \"\"\"\n",
    "        X_anomalies_encoded=preprocess_unsupervised(X_anomalies_encoded)\n",
    "        results = []\n",
    "\n",
    "        for idx in X_anomalies_encoded.index:\n",
    "            row_encoded = X_anomalies_encoded.loc[idx]\n",
    "            row_original = X_anomalies_original.loc[idx]\n",
    "            contribs = {}\n",
    "            values = {}\n",
    "\n",
    "            for col in self.features:\n",
    "                val_original = row_original[col]\n",
    "                val_encoded = row_encoded[col]\n",
    "                stat = self.stats_.get(col)\n",
    "\n",
    "                if stat[\"type\"] == \"numeric\":\n",
    "                    median = stat[\"median\"]\n",
    "                    iqr = stat[\"iqr\"]\n",
    "                    score = abs(val_original - median) / (iqr + 1e-8)\n",
    "                    contribs[col] = score\n",
    "                else:\n",
    "                    score = 0 if val_original == stat[\"top_value\"] else 1\n",
    "                    contribs[col] = score\n",
    "\n",
    "                values[col] = val_original\n",
    "\n",
    "            top_features = sorted(contribs.items(), key=lambda x: x[1], reverse=True)[:top_k]\n",
    "            formatted = [\n",
    "                f\"{col} = {values[col]} (score={contribs[col]:.2f})\" for col, _ in top_features\n",
    "            ]\n",
    "            explanation = {\n",
    "                \"index\": idx,\n",
    "                \"top_features\": formatted\n",
    "            }\n",
    "            results.append(explanation)\n",
    "\n",
    "        return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01b566cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnomalyExplainerV2:\n",
    "    def __init__(self, X, detector, method='pca', k=20):\n",
    "        \"\"\"\n",
    "        X : pd.DataFrame ou np.ndarray - Données complètes\n",
    "        detector : instance entraînée de AnomalyDetector\n",
    "        method : 'pca' ou 'umap' - Méthode de projection\n",
    "        k : int - Nombre de voisins pour le contexte local\n",
    "        \"\"\"\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            self.feature_names = X.columns.tolist()\n",
    "            self.X_raw = X.copy()\n",
    "        else:\n",
    "            self.feature_names = [f\"feature_{i}\" for i in range(X.shape[1])]\n",
    "            self.X_raw = pd.DataFrame(X, columns=self.feature_names)\n",
    "\n",
    "        self.detector = detector\n",
    "        self.k = k\n",
    "        self.method = method\n",
    "        self.scaler = StandardScaler()\n",
    "        self.X = self.scaler.fit_transform(self.X_raw)\n",
    "\n",
    "        self.anomalies_idx = np.where(self.detector.predict(self.X_raw) == 1)[0]\n",
    "        self.suspicion_scores = self.detector.predict_proba(self.X_raw)[:, 1]\n",
    "        self.anomaly_profiles = None\n",
    "        self.embedding = None\n",
    "\n",
    "    def compute_projection(self):\n",
    "        reducer = UMAP(n_neighbors=15, min_dist=0.1, random_state=42) if self.method == 'umap' else PCA(n_components=2)\n",
    "        self.embedding = reducer.fit_transform(self.X)\n",
    "\n",
    "    def explain_anomalies(self):\n",
    "        self.compute_projection()\n",
    "        profiles = []\n",
    "\n",
    "        for idx in self.anomalies_idx:\n",
    "            point = self.X[idx]\n",
    "            distances = np.linalg.norm(self.X - point, axis=1)\n",
    "            nearest_indices = np.argsort(distances)[1:self.k + 1]\n",
    "            local_mean = self.X[nearest_indices].mean(axis=0)\n",
    "            deviation = point - local_mean\n",
    "            strong_dims = np.argsort(np.abs(deviation))[::-1][:3]\n",
    "\n",
    "            profile = {\n",
    "                'index': idx,\n",
    "                'suspicion_score': self.suspicion_scores[idx],\n",
    "                'top_contributors': [self.feature_names[i] for i in strong_dims],\n",
    "                'deviation_vector': deviation[strong_dims],\n",
    "                'deviation_values': {self.feature_names[i]: float(deviation[i]) for i in strong_dims},\n",
    "                'real_values': {\n",
    "                    self.feature_names[i]: self.X_raw.iloc[idx][self.feature_names[i]] for i in strong_dims\n",
    "                },\n",
    "                'neighbor_means': {\n",
    "                    self.feature_names[i]: self.X_raw.iloc[nearest_indices][self.feature_names[i]].mean() for i in strong_dims\n",
    "                }\n",
    "            }\n",
    "            profiles.append(profile)\n",
    "\n",
    "        self.anomaly_profiles = profiles\n",
    "        return profiles\n",
    "\n",
    "    def plot_anomalies(self):\n",
    "        if self.embedding is None:\n",
    "            self.compute_projection()\n",
    "\n",
    "        plt.figure(figsize=(10, 7))\n",
    "        plt.scatter(self.embedding[:, 0], self.embedding[:, 1], c='lightgrey', s=20, label='Normaux')\n",
    "        scores = np.array([self.suspicion_scores[i] for i in self.anomalies_idx])\n",
    "        norm_scores = (scores - scores.min()) / (scores.max() - scores.min() + 1e-6)\n",
    "\n",
    "        scatter = plt.scatter(self.embedding[self.anomalies_idx, 0],\n",
    "                              self.embedding[self.anomalies_idx, 1],\n",
    "                              c=norm_scores, cmap='coolwarm', s=60, edgecolor='k', label='Anomalies')\n",
    "\n",
    "        plt.colorbar(scatter, label=\"Suspicion Score\")\n",
    "        plt.title(\"Projection des Données avec Anomalies\")\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    def generate_reports(self):\n",
    "        if self.anomaly_profiles is None:\n",
    "            self.explain_anomalies()\n",
    "\n",
    "        print(\"=== RAPPORT D’ANOMALIES ===\")\n",
    "        for profile in sorted(self.anomaly_profiles, key=lambda x: -x['suspicion_score']):\n",
    "            print(f\"Anomalie #{profile['index']}:\")\n",
    "            print(f\"  → Suspicion Score: {profile['suspicion_score']:.2f}\")\n",
    "            print(f\"  → Variables en cause: {', '.join(profile['top_contributors'])}\")\n",
    "            print(f\"  → Déviation relative: {profile['deviation_vector']}\")\n",
    "            print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ed63fe50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import torch\n",
    "\n",
    "def save_anomaly_model(anomaly_model, path_prefix=\"anomaly_detector\"):\n",
    "    # 1. Sauvegarder l'état du modèle PyTorch\n",
    "    torch.save(autoencoder.state_dict(), f\"{path_prefix}_autoencoder.pth\")\n",
    "    joblib.dump(autoencoder.lof, f\"{path_prefix}_lof.pkl\")\n",
    "    joblib.dump(autoencoder.iforest, f\"{path_prefix}_iforest.pkl\")\n",
    "    # 2. Sauvegarder le modèle ShrinkageBoostingClassifier\n",
    "    joblib.dump(anomaly_model.meta_model, f\"{path_prefix}_meta_model.pkl\")\n",
    "\n",
    "    # 3. Sauvegarder les paramètres du modèle\n",
    "    joblib.dump({\n",
    "        \"contamination\": anomaly_model.contamination,\n",
    "        \"features\": anomaly_model.features\n",
    "    }, f\"{path_prefix}_params.pkl\")\n",
    "\n",
    "    print(\"Modèle sauvegardé avec succès.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "94b6f6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_anomaly_model(path_prefix=\"anomaly_detector\", input_dim=10, latent_dim=16):\n",
    "    # 1. Recréer l'autoencodeur vide et charger les poids\n",
    "    autoencoder = Autoencoder(input_dim=input_dim, latent_dim=latent_dim)\n",
    "    autoencoder.load_state_dict(torch.load(f\"{path_prefix}_autoencoder.pth\"))\n",
    "    autoencoder.lof = joblib.load(f\"{path_prefix}_lof.pkl\")\n",
    "    autoencoder.iforest = joblib.load(f\"{path_prefix}_iforest.pkl\")\n",
    "    autoencoder.eval()\n",
    "\n",
    "    # 2. Recharger le modèle méta\n",
    "    meta_model = joblib.load(f\"{path_prefix}_meta_model.pkl\")\n",
    "\n",
    "    # 3. Recharger les paramètres\n",
    "    params = joblib.load(f\"{path_prefix}_params.pkl\")\n",
    "\n",
    "    # 4. Reconstruire l'objet AnomalyDetector\n",
    "    model = AnomalyDetector(autoencoder=autoencoder, contamination=params[\"contamination\"], features=params[\"features\"])\n",
    "    model.meta_model = meta_model\n",
    "\n",
    "    print(\"Modèle chargé avec succès.\")\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "173f0d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_final=['doc_scan_avant_activation', 'subscription_type', 'cn_valid', 'DOK_SCN_USR', 'type_d_operation', 'BU', 'lib_mois', 'Province', 'ID_doc']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eecb5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "'DOC_VAL_USR', 'status', 'Document_Validation_3G', 'ID_doc', 'doc_scan_avant_activation', 'Street', 'Document_Validation_4G', 'tarrif_profile', 'nin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9927773c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 - Loss: 0.0491\n",
      "Epoch 10 - Loss: 0.0001\n",
      "Epoch 20 - Loss: 0.0000\n",
      " Kmeans Silhouette Score: 1.000\n",
      "LOF Silhouette Score: 0.999\n",
      "Isolation Forest Silhouette Score: 1.000\n",
      "Anomalies détectées dans le test set : 33\n",
      "Total d'observations testées : 1289\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DOC_VAL_USR</th>\n",
       "      <th>status</th>\n",
       "      <th>Document_Validation_3G</th>\n",
       "      <th>ID_doc</th>\n",
       "      <th>doc_scan_avant_activation</th>\n",
       "      <th>Street</th>\n",
       "      <th>Document_Validation_4G</th>\n",
       "      <th>tarrif_profile</th>\n",
       "      <th>nin</th>\n",
       "      <th>anomaly</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4623</th>\n",
       "      <td>0.054376</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>0.054376</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6004</th>\n",
       "      <td>0.054376</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6127</th>\n",
       "      <td>0.054376</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>907</th>\n",
       "      <td>0.054376</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      DOC_VAL_USR  status  Document_Validation_3G  ID_doc  \\\n",
       "4623     0.054376     0.0                     0.0     0.0   \n",
       "233      0.054376     0.0                     0.0     0.0   \n",
       "6004     0.054376     0.0                     0.0     0.0   \n",
       "6127     0.054376     0.0                     0.0     0.0   \n",
       "907      0.054376     0.0                     0.0     0.0   \n",
       "\n",
       "      doc_scan_avant_activation  Street  Document_Validation_4G  \\\n",
       "4623                        0.0     0.0                     0.0   \n",
       "233                         0.0     0.0                     0.0   \n",
       "6004                        0.0     0.0                     0.0   \n",
       "6127                        0.0     0.0                     0.0   \n",
       "907                         0.0     0.0                     0.0   \n",
       "\n",
       "      tarrif_profile  nin  anomaly  \n",
       "4623             0.0  0.0        0  \n",
       "233              0.0  0.0        0  \n",
       "6004             0.0  0.0        0  \n",
       "6127             0.0  0.0        0  \n",
       "907              0.0  0.0        0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "selected_final=['DOC_VAL_USR', 'status', 'Document_Validation_3G', 'ID_doc', 'doc_scan_avant_activation', 'Street', 'Document_Validation_4G', 'tarrif_profile', 'nin']\n",
    "# data = df[selected_final].copy()\n",
    "X_preprocessed= preprocess_unsupervised(df[selected_final])\n",
    "\n",
    "df[selected_final] = X_preprocessed\n",
    "input_dim = len(selected_final)\n",
    "autoencoder = Autoencoder(input_dim=input_dim, latent_dim=16)\n",
    "# Séparation en train/test si tu veux valider\n",
    "X_train, X_test = train_test_split(df[selected_final], test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialisation du modèle avec les features finales\n",
    "anomaly_model = AnomalyDetector( autoencoder=autoencoder,contamination=0.05,features=selected_final) \n",
    "\n",
    "# Entraînement sur le train set\n",
    "anomaly_model.fit(X_train)\n",
    "\n",
    "# Prédiction sur le test set\n",
    "# predictions = anomaly_model.predict(X_test)\n",
    "predictions = anomaly_model.predict(X_test[selected_final])  # ou df[features]\n",
    "\n",
    "# Affichage des résultats\n",
    "print(\"Anomalies détectées dans le test set :\", sum(predictions))\n",
    "print(\"Total d'observations testées :\", len(predictions))\n",
    "\n",
    "# Pour analyse visuelle\n",
    "X_test_result = X_test.copy()\n",
    "X_test_result[\"anomaly\"] = predictions\n",
    "X_test_result.to_csv(\"anomalies_detected.csv\", index=False)\n",
    "X_test_result.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "294d2153",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 - Loss: 0.0946\n",
      "Epoch 10 - Loss: 0.0000\n",
      "Epoch 20 - Loss: 0.0000\n",
      " Kmeans Silhouette Score: 1.000\n",
      "LOF Silhouette Score: 0.999\n",
      "Isolation Forest Silhouette Score: 1.000\n",
      "Total anomalies détectées : 33\n"
     ]
    }
   ],
   "source": [
    "# 1️⃣ Conserver un DataFrame original intact avant encodage\n",
    "df_original = df.copy()\n",
    "\n",
    "# 2️⃣ Sélectionner uniquement les colonnes à encoder pour le modèle\n",
    "X_to_encode = df[selected_final].copy()\n",
    "\n",
    "# 3️⃣ Encodage\n",
    "X_preprocessed = preprocess_unsupervised(X_to_encode)\n",
    "\n",
    "# 4️⃣ Split train/test basé sur les données encodées, mais index liés aux données originales\n",
    "X_train, X_test = train_test_split(X_preprocessed, test_size=0.2, random_state=42)\n",
    "\n",
    "# 5️⃣ Entraînement et prédictions\n",
    "anomaly_model.fit(X_train)\n",
    "predictions = anomaly_model.predict(X_test)\n",
    "\n",
    "# 6️⃣ Récupérer toutes les colonnes originales associées au test set\n",
    "X_test_original = df.loc[X_test.index].copy()\n",
    "X_test_original[\"anomaly\"] = predictions\n",
    "\n",
    "# 7️⃣ Export complet avec toutes les colonnes originales intactes\n",
    "X_test_original.to_csv(\"anomalies_detected_full_original.csv\", index=False)\n",
    "\n",
    "# 8️⃣ Export uniquement des anomalies détectées\n",
    "df_anomalies_only = X_test_original[X_test_original[\"anomaly\"] == 1]\n",
    "df_anomalies_only.to_csv(\"anomalies_detected_original_only.csv\", index=False)\n",
    "\n",
    "# Vérification\n",
    "print(f\"Total anomalies détectées : {df_anomalies_only.shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a87714cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['nin', 'status', 'status_date', 'Birth_date', 'age_sub', 'Gender',\n",
       "       'id_type', 'subscription_type', 'tarrif_profile', 'type_sim',\n",
       "       'Activation_Date', 'First_Call_Date', 'Last_Call_Date', 'ID_doc',\n",
       "       'Document_Validation_2G', 'Document_Validation_3G',\n",
       "       'Document_Validation_4G', 'Document_stamped', 'document_scaned_status',\n",
       "       'Document_Validation_Date', 'DOC_SCN_DT', 'pdv_sk', 'PoS_ID',\n",
       "       'DOC_VAL_USR', 'DOK_SCN_USR', 'BU', 'localisation_sk', 'Postal_ID',\n",
       "       'Province', 'City', 'Street', 'id_date', 'full_date', 'year', 'mois',\n",
       "       'lib_mois', 'jours', 'lib_jour', 'NIN_ok', 'DOB_ok', 'minor_ok',\n",
       "       'cn_valid', 'similarity_score', 'ocr_violation', 'id_operation',\n",
       "       'type_d_operation', 'similarity_score_bin', 'violation_reason',\n",
       "       'temps_moyen_appel', 'temps_moyen_traitement', 'reactivite_client',\n",
       "       'Revenue_Last_2_Months', 'Revenue_Last_12_Months', 'ARPU_Last_2_Months',\n",
       "       'segment_value', 'client_haut_revenue', 'doc_scan_avant_activation',\n",
       "       'score_confiance', 'anomaly'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_original.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "129bb441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette score (latents, selon prédiction métamodèle) : 0.9522\n",
      "Taux moyen de désaccord (0 à 3) avec les modèles de base : 0.0116\n",
      "\n",
      "Statistiques d'erreur de reconstruction selon la classe prédite :\n",
      "            count          mean           std           min           25%  \\\n",
      "meta_pred                                                                   \n",
      "0          1256.0  2.074548e-17  6.367606e-18  2.004569e-17  2.004569e-17   \n",
      "1            33.0  2.749858e-16  1.259502e-16  1.341520e-16  1.788693e-16   \n",
      "\n",
      "                    50%           75%           max  \n",
      "meta_pred                                            \n",
      "0          2.004569e-17  2.004569e-17  7.864080e-17  \n",
      "1          2.914335e-16  2.914335e-16  5.720732e-16  \n"
     ]
    }
   ],
   "source": [
    "anomaly_model.evaluate_unsupervised(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b6c11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Si id_fact est bien présent dans X_test_result :\n",
    "merged_df = df.merge(X_test_result[['id_fact', 'anomaly']], on='id_fact', how='left')\n",
    "\n",
    "# 'anomaly' sera NaN pour les lignes non présentes dans X_test (i.e., le train)\n",
    "merged_df['anomaly'] = merged_df['anomaly'].fillna(0).astype(int)\n",
    "\n",
    "# Sauvegarde si besoin :\n",
    "merged_df.to_csv(\"df_with_anomalies.csv\", index=False)\n",
    "\n",
    "# Vérification rapide :\n",
    "merged_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "93f72d77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modèle sauvegardé avec succès.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\IMENE\\AppData\\Local\\Temp\\ipykernel_16780\\2157438703.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  autoencoder.load_state_dict(torch.load(f\"{path_prefix}_autoencoder.pth\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modèle chargé avec succès.\n"
     ]
    }
   ],
   "source": [
    "# Sauvegarde\n",
    "save_anomaly_model(anomaly_model, path_prefix=\"anomaly_detector\")\n",
    "\n",
    "# Rechargement\n",
    "loaded_model = load_anomaly_model(path_prefix=\"anomaly_detector\", input_dim=input_dim, latent_dim=16)\n",
    "\n",
    "# Utilisation après chargement\n",
    "predictions = loaded_model.predict(X_test[selected_final])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9f26e04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35622939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 - Loss: 0.0899\n",
      "Epoch 10 - Loss: 0.0001\n",
      "Epoch 20 - Loss: 0.0004\n",
      " Kmeans Silhouette Score: 0.981\n",
      "LOF Silhouette Score: 0.948\n",
      "Isolation Forest Silhouette Score: 0.964\n",
      "Anomalies détectées dans le test set : 48\n",
      "Total d'observations testées : 1289\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_scan_avant_activation</th>\n",
       "      <th>subscription_type</th>\n",
       "      <th>cn_valid</th>\n",
       "      <th>DOK_SCN_USR</th>\n",
       "      <th>type_d_operation</th>\n",
       "      <th>BU</th>\n",
       "      <th>lib_mois</th>\n",
       "      <th>Province</th>\n",
       "      <th>ID_doc</th>\n",
       "      <th>anomaly</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4623</th>\n",
       "      <td>0.054376</td>\n",
       "      <td>0.417333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>0.054376</td>\n",
       "      <td>0.417333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6004</th>\n",
       "      <td>0.054376</td>\n",
       "      <td>0.417333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6127</th>\n",
       "      <td>0.054376</td>\n",
       "      <td>0.417333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>907</th>\n",
       "      <td>0.054376</td>\n",
       "      <td>0.417333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      doc_scan_avant_activation  subscription_type  cn_valid  DOK_SCN_USR  \\\n",
       "4623                   0.054376           0.417333       0.0          0.0   \n",
       "233                    0.054376           0.417333       0.0          0.0   \n",
       "6004                   0.054376           0.417333       0.0          0.0   \n",
       "6127                   0.054376           0.417333       0.0          0.0   \n",
       "907                    0.054376           0.417333       0.0          0.0   \n",
       "\n",
       "      type_d_operation   BU  lib_mois  Province  ID_doc  anomaly  \n",
       "4623               0.0  0.0       0.0       0.0     0.0        0  \n",
       "233                0.0  0.0       0.0       0.0     0.0        0  \n",
       "6004               0.0  0.0       0.0       0.0     0.0        0  \n",
       "6127               0.0  0.0       0.0       0.0     0.0        0  \n",
       "907                0.0  0.0       0.0       0.0     0.0        0  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "selected_final=['doc_scan_avant_activation', 'subscription_type', 'cn_valid', 'DOK_SCN_USR', 'type_d_operation', 'BU', 'lib_mois', 'Province', 'ID_doc']\n",
    "# data = df[selected_final].copy()\n",
    "X_preprocessed= preprocess_unsupervised(df[selected_final])\n",
    "\n",
    "df[selected_final] = X_preprocessed\n",
    "input_dim = len(selected_final)\n",
    "autoencoder = Autoencoder(input_dim=input_dim, latent_dim=16)\n",
    "# Séparation en train/test si tu veux valider\n",
    "X_train, X_test = train_test_split(df[selected_final], test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialisation du modèle avec les features finales\n",
    "anomaly_model = AnomalyDetector( autoencoder=autoencoder,contamination=0.05,features=selected_final) \n",
    "\n",
    "# Entraînement sur le train set\n",
    "anomaly_model.fit(X_train)\n",
    "\n",
    "# Prédiction sur le test set\n",
    "# predictions = anomaly_model.predict(X_test)\n",
    "predictions = anomaly_model.predict(X_test[selected_final])  # ou df[features]\n",
    "\n",
    "# Affichage des résultats\n",
    "print(\"Anomalies détectées dans le test set :\", sum(predictions))\n",
    "print(\"Total d'observations testées :\", len(predictions))\n",
    "\n",
    "# Pour analyse visuelle\n",
    "X_test_result = X_test.copy()\n",
    "X_test_result[\"anomaly\"] = predictions\n",
    "df_anomaly = X_test_result[X_test_result[\"anomaly\"] == 1].to_csv(\"anomalies_detected.csv\", index=False)\n",
    "X_test_result.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b1c266f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette score (latents, selon prédiction métamodèle) : 0.6722\n",
      "Taux moyen de désaccord (0 à 3) avec les modèles de base : 0.0442\n",
      "\n",
      "Statistiques d'erreur de reconstruction selon la classe prédite :\n",
      "            count          mean           std           min           25%  \\\n",
      "meta_pred                                                                   \n",
      "0          1241.0  2.076497e-07  1.832897e-07  1.366576e-07  1.366576e-07   \n",
      "1            48.0  1.294431e-03  4.337866e-03  1.366588e-07  1.366593e-07   \n",
      "\n",
      "                    50%           75%           max  \n",
      "meta_pred                                            \n",
      "0          1.366576e-07  1.366576e-07  6.804920e-07  \n",
      "1          1.366601e-07  1.366611e-07  1.553085e-02  \n"
     ]
    }
   ],
   "source": [
    "anomaly_model.evaluate_unsupervised(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "545d253b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_top_frequent_values_plot(df_anomalies, column, top_n=10, df_original=None):\n",
    "    \"\"\"\n",
    "    Affiche les top valeurs non encodées d'une colonne dans les anomalies.\n",
    "    Si les données originales sont disponibles, elles sont utilisées.\n",
    "    \"\"\"\n",
    "    if df_original is not None and column in df_original.columns:\n",
    "        # Valeurs originales (non encodées)\n",
    "        original_values = df_original.loc[df_anomalies.index, column]\n",
    "    else:\n",
    "        # Sinon fallback sur valeurs transformées (mais potentiellement encodées)\n",
    "        original_values = df_anomalies[column]\n",
    "\n",
    "    # Calcul des fréquences\n",
    "    top_vals = original_values.value_counts().head(top_n).reset_index()\n",
    "    top_vals.columns = ['value', 'count']\n",
    "\n",
    "    fig = px.bar(\n",
    "        top_vals,\n",
    "        x='value',\n",
    "        y='count',\n",
    "        title=f\"Top {top_n} valeurs non encodées de '{column}' dans les anomalies\",\n",
    "        labels={'value': column, 'count': 'Fréquence'},\n",
    "        color='count',\n",
    "        color_continuous_scale=px.colors.sequential.Viridis\n",
    "    )\n",
    "\n",
    "    fig.update_layout(\n",
    "        xaxis_tickangle=-45,\n",
    "        margin=dict(l=20, r=20, t=40, b=20)\n",
    "    )\n",
    "\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ce218c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "anomaly_explainer= AnomalyExplainerV2(X=X_test[selected_final], detector=anomaly_model, method='UMAP', k=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "887ec219",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x700 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== RAPPORT D’ANOMALIES ===\n",
      "Anomalie #126:\n",
      "  → Suspicion Score: 1.00\n",
      "  → Variables en cause: subscription_type, doc_scan_avant_activation, ID_doc\n",
      "  → Déviation relative: [2.9802322e-08 1.8626451e-08 0.0000000e+00]\n",
      "--------------------------------------------------\n",
      "Anomalie #127:\n",
      "  → Suspicion Score: 1.00\n",
      "  → Variables en cause: subscription_type, doc_scan_avant_activation, ID_doc\n",
      "  → Déviation relative: [2.9802322e-08 1.8626451e-08 0.0000000e+00]\n",
      "--------------------------------------------------\n",
      "Anomalie #128:\n",
      "  → Suspicion Score: 1.00\n",
      "  → Variables en cause: subscription_type, doc_scan_avant_activation, ID_doc\n",
      "  → Déviation relative: [2.9802322e-08 1.8626451e-08 0.0000000e+00]\n",
      "--------------------------------------------------\n",
      "Anomalie #238:\n",
      "  → Suspicion Score: 1.00\n",
      "  → Variables en cause: doc_scan_avant_activation, subscription_type, ID_doc\n",
      "  → Déviation relative: [-1.5282356e+01  2.9802322e-08  0.0000000e+00]\n",
      "--------------------------------------------------\n",
      "Anomalie #255:\n",
      "  → Suspicion Score: 1.00\n",
      "  → Variables en cause: subscription_type, doc_scan_avant_activation, ID_doc\n",
      "  → Déviation relative: [2.9802322e-08 1.8626451e-08 0.0000000e+00]\n",
      "--------------------------------------------------\n",
      "Anomalie #257:\n",
      "  → Suspicion Score: 1.00\n",
      "  → Variables en cause: subscription_type, doc_scan_avant_activation, ID_doc\n",
      "  → Déviation relative: [2.9802322e-08 1.8626451e-08 0.0000000e+00]\n",
      "--------------------------------------------------\n",
      "Anomalie #322:\n",
      "  → Suspicion Score: 1.00\n",
      "  → Variables en cause: doc_scan_avant_activation, subscription_type, ID_doc\n",
      "  → Déviation relative: [-1.5282356e+01  2.9802322e-08  0.0000000e+00]\n",
      "--------------------------------------------------\n",
      "Anomalie #384:\n",
      "  → Suspicion Score: 1.00\n",
      "  → Variables en cause: subscription_type, doc_scan_avant_activation, ID_doc\n",
      "  → Déviation relative: [2.9802322e-08 1.8626451e-08 0.0000000e+00]\n",
      "--------------------------------------------------\n",
      "Anomalie #385:\n",
      "  → Suspicion Score: 1.00\n",
      "  → Variables en cause: subscription_type, doc_scan_avant_activation, ID_doc\n",
      "  → Déviation relative: [2.9802322e-08 1.8626451e-08 0.0000000e+00]\n",
      "--------------------------------------------------\n",
      "Anomalie #386:\n",
      "  → Suspicion Score: 1.00\n",
      "  → Variables en cause: subscription_type, doc_scan_avant_activation, ID_doc\n",
      "  → Déviation relative: [2.9802322e-08 1.8626451e-08 0.0000000e+00]\n",
      "--------------------------------------------------\n",
      "Anomalie #513:\n",
      "  → Suspicion Score: 1.00\n",
      "  → Variables en cause: subscription_type, doc_scan_avant_activation, ID_doc\n",
      "  → Déviation relative: [2.9802322e-08 1.8626451e-08 0.0000000e+00]\n",
      "--------------------------------------------------\n",
      "Anomalie #514:\n",
      "  → Suspicion Score: 1.00\n",
      "  → Variables en cause: subscription_type, doc_scan_avant_activation, ID_doc\n",
      "  → Déviation relative: [2.9802322e-08 1.8626451e-08 0.0000000e+00]\n",
      "--------------------------------------------------\n",
      "Anomalie #515:\n",
      "  → Suspicion Score: 1.00\n",
      "  → Variables en cause: subscription_type, doc_scan_avant_activation, ID_doc\n",
      "  → Déviation relative: [2.9802322e-08 1.8626451e-08 0.0000000e+00]\n",
      "--------------------------------------------------\n",
      "Anomalie #642:\n",
      "  → Suspicion Score: 1.00\n",
      "  → Variables en cause: subscription_type, doc_scan_avant_activation, ID_doc\n",
      "  → Déviation relative: [2.9802322e-08 1.8626451e-08 0.0000000e+00]\n",
      "--------------------------------------------------\n",
      "Anomalie #643:\n",
      "  → Suspicion Score: 1.00\n",
      "  → Variables en cause: subscription_type, doc_scan_avant_activation, ID_doc\n",
      "  → Déviation relative: [2.9802322e-08 1.8626451e-08 0.0000000e+00]\n",
      "--------------------------------------------------\n",
      "Anomalie #644:\n",
      "  → Suspicion Score: 1.00\n",
      "  → Variables en cause: subscription_type, doc_scan_avant_activation, ID_doc\n",
      "  → Déviation relative: [2.9802322e-08 1.8626451e-08 0.0000000e+00]\n",
      "--------------------------------------------------\n",
      "Anomalie #772:\n",
      "  → Suspicion Score: 1.00\n",
      "  → Variables en cause: subscription_type, doc_scan_avant_activation, ID_doc\n",
      "  → Déviation relative: [2.9802322e-08 1.8626451e-08 0.0000000e+00]\n",
      "--------------------------------------------------\n",
      "Anomalie #773:\n",
      "  → Suspicion Score: 1.00\n",
      "  → Variables en cause: subscription_type, doc_scan_avant_activation, ID_doc\n",
      "  → Déviation relative: [2.9802322e-08 1.8626451e-08 0.0000000e+00]\n",
      "--------------------------------------------------\n",
      "Anomalie #796:\n",
      "  → Suspicion Score: 1.00\n",
      "  → Variables en cause: doc_scan_avant_activation, subscription_type, ID_doc\n",
      "  → Déviation relative: [-1.5282356e+01  2.9802322e-08  0.0000000e+00]\n",
      "--------------------------------------------------\n",
      "Anomalie #900:\n",
      "  → Suspicion Score: 1.00\n",
      "  → Variables en cause: subscription_type, doc_scan_avant_activation, ID_doc\n",
      "  → Déviation relative: [2.9802322e-08 1.8626451e-08 0.0000000e+00]\n",
      "--------------------------------------------------\n",
      "Anomalie #901:\n",
      "  → Suspicion Score: 1.00\n",
      "  → Variables en cause: subscription_type, doc_scan_avant_activation, ID_doc\n",
      "  → Déviation relative: [2.9802322e-08 1.8626451e-08 0.0000000e+00]\n",
      "--------------------------------------------------\n",
      "Anomalie #1029:\n",
      "  → Suspicion Score: 1.00\n",
      "  → Variables en cause: subscription_type, doc_scan_avant_activation, ID_doc\n",
      "  → Déviation relative: [2.9802322e-08 1.8626451e-08 0.0000000e+00]\n",
      "--------------------------------------------------\n",
      "Anomalie #1030:\n",
      "  → Suspicion Score: 1.00\n",
      "  → Variables en cause: subscription_type, doc_scan_avant_activation, ID_doc\n",
      "  → Déviation relative: [2.9802322e-08 1.8626451e-08 0.0000000e+00]\n",
      "--------------------------------------------------\n",
      "Anomalie #1031:\n",
      "  → Suspicion Score: 1.00\n",
      "  → Variables en cause: subscription_type, doc_scan_avant_activation, ID_doc\n",
      "  → Déviation relative: [2.9802322e-08 1.8626451e-08 0.0000000e+00]\n",
      "--------------------------------------------------\n",
      "Anomalie #1158:\n",
      "  → Suspicion Score: 1.00\n",
      "  → Variables en cause: subscription_type, doc_scan_avant_activation, ID_doc\n",
      "  → Déviation relative: [2.9802322e-08 1.8626451e-08 0.0000000e+00]\n",
      "--------------------------------------------------\n",
      "Anomalie #1159:\n",
      "  → Suspicion Score: 1.00\n",
      "  → Variables en cause: subscription_type, doc_scan_avant_activation, ID_doc\n",
      "  → Déviation relative: [2.9802322e-08 1.8626451e-08 0.0000000e+00]\n",
      "--------------------------------------------------\n",
      "Anomalie #1160:\n",
      "  → Suspicion Score: 1.00\n",
      "  → Variables en cause: subscription_type, doc_scan_avant_activation, ID_doc\n",
      "  → Déviation relative: [2.9802322e-08 1.8626451e-08 0.0000000e+00]\n",
      "--------------------------------------------------\n",
      "Anomalie #1256:\n",
      "  → Suspicion Score: 1.00\n",
      "  → Variables en cause: doc_scan_avant_activation, subscription_type, ID_doc\n",
      "  → Déviation relative: [-1.5282356e+01  2.9802322e-08  0.0000000e+00]\n",
      "--------------------------------------------------\n",
      "Anomalie #1287:\n",
      "  → Suspicion Score: 1.00\n",
      "  → Variables en cause: subscription_type, doc_scan_avant_activation, ID_doc\n",
      "  → Déviation relative: [2.9802322e-08 1.8626451e-08 0.0000000e+00]\n",
      "--------------------------------------------------\n",
      "Anomalie #1288:\n",
      "  → Suspicion Score: 1.00\n",
      "  → Variables en cause: subscription_type, doc_scan_avant_activation, ID_doc\n",
      "  → Déviation relative: [2.9802322e-08 1.8626451e-08 0.0000000e+00]\n",
      "--------------------------------------------------\n",
      "Anomalie #174:\n",
      "  → Suspicion Score: 0.56\n",
      "  → Variables en cause: subscription_type, doc_scan_avant_activation, ID_doc\n",
      "  → Déviation relative: [2.9802322e-08 1.8626451e-08 0.0000000e+00]\n",
      "--------------------------------------------------\n",
      "Anomalie #175:\n",
      "  → Suspicion Score: 0.56\n",
      "  → Variables en cause: subscription_type, doc_scan_avant_activation, ID_doc\n",
      "  → Déviation relative: [2.9802322e-08 1.8626451e-08 0.0000000e+00]\n",
      "--------------------------------------------------\n",
      "Anomalie #176:\n",
      "  → Suspicion Score: 0.56\n",
      "  → Variables en cause: subscription_type, doc_scan_avant_activation, ID_doc\n",
      "  → Déviation relative: [2.9802322e-08 1.8626451e-08 0.0000000e+00]\n",
      "--------------------------------------------------\n",
      "Anomalie #256:\n",
      "  → Suspicion Score: 0.56\n",
      "  → Variables en cause: doc_scan_avant_activation, ID_doc, Province\n",
      "  → Déviation relative: [1.8626451e-08 0.0000000e+00 0.0000000e+00]\n",
      "--------------------------------------------------\n",
      "Anomalie #432:\n",
      "  → Suspicion Score: 0.56\n",
      "  → Variables en cause: subscription_type, doc_scan_avant_activation, ID_doc\n",
      "  → Déviation relative: [2.9802322e-08 1.8626451e-08 0.0000000e+00]\n",
      "--------------------------------------------------\n",
      "Anomalie #433:\n",
      "  → Suspicion Score: 0.56\n",
      "  → Variables en cause: doc_scan_avant_activation, ID_doc, Province\n",
      "  → Déviation relative: [1.8626451e-08 0.0000000e+00 0.0000000e+00]\n",
      "--------------------------------------------------\n",
      "Anomalie #434:\n",
      "  → Suspicion Score: 0.56\n",
      "  → Variables en cause: subscription_type, doc_scan_avant_activation, ID_doc\n",
      "  → Déviation relative: [2.9802322e-08 1.8626451e-08 0.0000000e+00]\n",
      "--------------------------------------------------\n",
      "Anomalie #690:\n",
      "  → Suspicion Score: 0.56\n",
      "  → Variables en cause: doc_scan_avant_activation, ID_doc, Province\n",
      "  → Déviation relative: [1.8626451e-08 0.0000000e+00 0.0000000e+00]\n",
      "--------------------------------------------------\n",
      "Anomalie #691:\n",
      "  → Suspicion Score: 0.56\n",
      "  → Variables en cause: doc_scan_avant_activation, ID_doc, Province\n",
      "  → Déviation relative: [1.8626451e-08 0.0000000e+00 0.0000000e+00]\n",
      "--------------------------------------------------\n",
      "Anomalie #692:\n",
      "  → Suspicion Score: 0.56\n",
      "  → Variables en cause: subscription_type, doc_scan_avant_activation, ID_doc\n",
      "  → Déviation relative: [2.9802322e-08 1.8626451e-08 0.0000000e+00]\n",
      "--------------------------------------------------\n",
      "Anomalie #771:\n",
      "  → Suspicion Score: 0.56\n",
      "  → Variables en cause: doc_scan_avant_activation, ID_doc, Province\n",
      "  → Déviation relative: [1.8626451e-08 0.0000000e+00 0.0000000e+00]\n",
      "--------------------------------------------------\n",
      "Anomalie #902:\n",
      "  → Suspicion Score: 0.56\n",
      "  → Variables en cause: doc_scan_avant_activation, ID_doc, Province\n",
      "  → Déviation relative: [1.8626451e-08 0.0000000e+00 0.0000000e+00]\n",
      "--------------------------------------------------\n",
      "Anomalie #948:\n",
      "  → Suspicion Score: 0.56\n",
      "  → Variables en cause: subscription_type, doc_scan_avant_activation, ID_doc\n",
      "  → Déviation relative: [2.9802322e-08 1.8626451e-08 0.0000000e+00]\n",
      "--------------------------------------------------\n",
      "Anomalie #949:\n",
      "  → Suspicion Score: 0.56\n",
      "  → Variables en cause: subscription_type, doc_scan_avant_activation, ID_doc\n",
      "  → Déviation relative: [2.9802322e-08 1.8626451e-08 0.0000000e+00]\n",
      "--------------------------------------------------\n",
      "Anomalie #950:\n",
      "  → Suspicion Score: 0.56\n",
      "  → Variables en cause: subscription_type, doc_scan_avant_activation, ID_doc\n",
      "  → Déviation relative: [2.9802322e-08 1.8626451e-08 0.0000000e+00]\n",
      "--------------------------------------------------\n",
      "Anomalie #1206:\n",
      "  → Suspicion Score: 0.56\n",
      "  → Variables en cause: subscription_type, doc_scan_avant_activation, ID_doc\n",
      "  → Déviation relative: [2.9802322e-08 1.8626451e-08 0.0000000e+00]\n",
      "--------------------------------------------------\n",
      "Anomalie #1207:\n",
      "  → Suspicion Score: 0.56\n",
      "  → Variables en cause: subscription_type, doc_scan_avant_activation, ID_doc\n",
      "  → Déviation relative: [2.9802322e-08 1.8626451e-08 0.0000000e+00]\n",
      "--------------------------------------------------\n",
      "Anomalie #1208:\n",
      "  → Suspicion Score: 0.56\n",
      "  → Variables en cause: subscription_type, doc_scan_avant_activation, ID_doc\n",
      "  → Déviation relative: [2.9802322e-08 1.8626451e-08 0.0000000e+00]\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "anomaly_explainer.explain_anomalies()\n",
    "anomaly_explainer.plot_anomalies()\n",
    "anomaly_explainer.generate_reports()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "70f82f4d",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 264\u001b[0m\n\u001b[0;32m    125\u001b[0m home_layout \u001b[38;5;241m=\u001b[39m dbc\u001b[38;5;241m.\u001b[39mContainer([\n\u001b[0;32m    126\u001b[0m     dbc\u001b[38;5;241m.\u001b[39mRow([\n\u001b[0;32m    127\u001b[0m         dbc\u001b[38;5;241m.\u001b[39mCol(html\u001b[38;5;241m.\u001b[39mH1(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTableau de Bord\u001b[39m\u001b[38;5;124m\"\u001b[39m, className\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext-center mb-4\u001b[39m\u001b[38;5;124m'\u001b[39m), width\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m12\u001b[39m)\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    206\u001b[0m     ])\n\u001b[0;32m    207\u001b[0m ], fluid\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    208\u001b[0m \u001b[38;5;66;03m# Layout de la page d'analyse des anomalies\u001b[39;00m\n\u001b[0;32m    209\u001b[0m anomaly_analysis_layout \u001b[38;5;241m=\u001b[39m dbc\u001b[38;5;241m.\u001b[39mContainer([\n\u001b[0;32m    210\u001b[0m     dbc\u001b[38;5;241m.\u001b[39mRow([\n\u001b[0;32m    211\u001b[0m         dbc\u001b[38;5;241m.\u001b[39mCol(html\u001b[38;5;241m.\u001b[39mH1(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAnalyse Détailée des Anomalies\u001b[39m\u001b[38;5;124m\"\u001b[39m, className\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext-center mb-4\u001b[39m\u001b[38;5;124m'\u001b[39m), width\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m12\u001b[39m)\n\u001b[0;32m    212\u001b[0m     ]),\n\u001b[0;32m    213\u001b[0m     \n\u001b[0;32m    214\u001b[0m     \u001b[38;5;66;03m# Analyse des Features Importantes\u001b[39;00m\n\u001b[0;32m    215\u001b[0m     dbc\u001b[38;5;241m.\u001b[39mRow([\n\u001b[0;32m    216\u001b[0m         dbc\u001b[38;5;241m.\u001b[39mCol([\n\u001b[0;32m    217\u001b[0m             dbc\u001b[38;5;241m.\u001b[39mCard([\n\u001b[0;32m    218\u001b[0m                 dbc\u001b[38;5;241m.\u001b[39mCardHeader(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContribution des Variables aux Anomalies\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    219\u001b[0m                 dbc\u001b[38;5;241m.\u001b[39mCardBody([\n\u001b[0;32m    220\u001b[0m                     dcc\u001b[38;5;241m.\u001b[39mGraph(\u001b[38;5;28mid\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeature-importance\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    221\u001b[0m                 ])\n\u001b[0;32m    222\u001b[0m             ])\n\u001b[0;32m    223\u001b[0m         ], width\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m12\u001b[39m)\n\u001b[0;32m    224\u001b[0m     ]),\n\u001b[0;32m    225\u001b[0m     \n\u001b[0;32m    226\u001b[0m     \u001b[38;5;66;03m# Détails des Anomalies\u001b[39;00m\n\u001b[0;32m    227\u001b[0m     dbc\u001b[38;5;241m.\u001b[39mRow([\n\u001b[0;32m    228\u001b[0m         dbc\u001b[38;5;241m.\u001b[39mCol([\n\u001b[0;32m    229\u001b[0m             dbc\u001b[38;5;241m.\u001b[39mCard([\n\u001b[0;32m    230\u001b[0m                 dbc\u001b[38;5;241m.\u001b[39mCardHeader(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDétails des Anomalies Détectées\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    231\u001b[0m                 dbc\u001b[38;5;241m.\u001b[39mCardBody([\n\u001b[0;32m    232\u001b[0m                     html\u001b[38;5;241m.\u001b[39mLabel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSélectionnez une anomalie pour plus de détails:\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    233\u001b[0m                     dcc\u001b[38;5;241m.\u001b[39mDropdown(\n\u001b[0;32m    234\u001b[0m                         \u001b[38;5;28mid\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124manomaly-selector\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    235\u001b[0m                         options\u001b[38;5;241m=\u001b[39m[{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAnomalie \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m'\u001b[39m: idx} \n\u001b[0;32m    236\u001b[0m                                 \u001b[38;5;28;01mfor\u001b[39;00m i, idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(anomaly_explainer\u001b[38;5;241m.\u001b[39manomalies_idx)],\n\u001b[0;32m    237\u001b[0m                         value\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    238\u001b[0m                     ),\n\u001b[0;32m    239\u001b[0m                     html\u001b[38;5;241m.\u001b[39mDiv(\u001b[38;5;28mid\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124manomaly-details\u001b[39m\u001b[38;5;124m'\u001b[39m, className\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmt-3\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    240\u001b[0m                 ])\n\u001b[0;32m    241\u001b[0m             ])\n\u001b[0;32m    242\u001b[0m         ], width\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m12\u001b[39m)\n\u001b[0;32m    243\u001b[0m     ], className\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmt-4\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[0;32m    244\u001b[0m     \n\u001b[0;32m    245\u001b[0m     dbc\u001b[38;5;241m.\u001b[39mRow([\n\u001b[0;32m    246\u001b[0m         dbc\u001b[38;5;241m.\u001b[39mCol([\n\u001b[0;32m    247\u001b[0m             dbc\u001b[38;5;241m.\u001b[39mCard([\n\u001b[0;32m    248\u001b[0m                 dbc\u001b[38;5;241m.\u001b[39mCardHeader(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAnalyse Comparative\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    249\u001b[0m                 dbc\u001b[38;5;241m.\u001b[39mCardBody([\n\u001b[0;32m    250\u001b[0m                     dbc\u001b[38;5;241m.\u001b[39mRow([\n\u001b[0;32m    251\u001b[0m                         dbc\u001b[38;5;241m.\u001b[39mCol([\n\u001b[0;32m    252\u001b[0m                             html\u001b[38;5;241m.\u001b[39mLabel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVariable X:\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    253\u001b[0m                             dcc\u001b[38;5;241m.\u001b[39mDropdown(\n\u001b[0;32m    254\u001b[0m                                 \u001b[38;5;28mid\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscatter-x\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    255\u001b[0m                                 options\u001b[38;5;241m=\u001b[39m[{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m: col, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m'\u001b[39m: col} \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m numeric_cols],\n\u001b[0;32m    256\u001b[0m                                 value\u001b[38;5;241m=\u001b[39mnumeric_cols[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    257\u001b[0m                             )\n\u001b[0;32m    258\u001b[0m                         ], md\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m6\u001b[39m),\n\u001b[0;32m    259\u001b[0m                         dbc\u001b[38;5;241m.\u001b[39mCol([\n\u001b[0;32m    260\u001b[0m                             html\u001b[38;5;241m.\u001b[39mLabel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVariable Y:\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    261\u001b[0m                             dcc\u001b[38;5;241m.\u001b[39mDropdown(\n\u001b[0;32m    262\u001b[0m                                 \u001b[38;5;28mid\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscatter-y\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    263\u001b[0m                                 options\u001b[38;5;241m=\u001b[39m[{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m: col, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m'\u001b[39m: col} \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m numeric_cols],\n\u001b[1;32m--> 264\u001b[0m                                 value\u001b[38;5;241m=\u001b[39m\u001b[43mnumeric_cols\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m    265\u001b[0m                             )\n\u001b[0;32m    266\u001b[0m                         ], md\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m6\u001b[39m)\n\u001b[0;32m    267\u001b[0m                     ]),\n\u001b[0;32m    268\u001b[0m                     dcc\u001b[38;5;241m.\u001b[39mGraph(\u001b[38;5;28mid\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcomparative-scatter\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    269\u001b[0m                 ])\n\u001b[0;32m    270\u001b[0m             ])\n\u001b[0;32m    271\u001b[0m         ])\n\u001b[0;32m    272\u001b[0m     ]),\n\u001b[0;32m    273\u001b[0m     \u001b[38;5;66;03m# Bouton de retour\u001b[39;00m\n\u001b[0;32m    274\u001b[0m     dbc\u001b[38;5;241m.\u001b[39mRow([\n\u001b[0;32m    275\u001b[0m         dbc\u001b[38;5;241m.\u001b[39mCol(\n\u001b[0;32m    276\u001b[0m             dbc\u001b[38;5;241m.\u001b[39mButton(\n\u001b[0;32m    277\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRetour au tableau de bord\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[0;32m    278\u001b[0m                 color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msecondary\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[0;32m    279\u001b[0m                 href\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    280\u001b[0m                 className\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmt-4\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    281\u001b[0m             ),\n\u001b[0;32m    282\u001b[0m             width\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m12\u001b[39m, className\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext-center\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    283\u001b[0m         )\n\u001b[0;32m    284\u001b[0m     ])\n\u001b[0;32m    285\u001b[0m ], fluid\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    286\u001b[0m anomalies \u001b[38;5;241m=\u001b[39m X_test_result[X_test_result[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124manomaly\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    287\u001b[0m \u001b[38;5;66;03m# Layout de la page des valeurs fréquentes\u001b[39;00m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "import dash\n",
    "from dash import dcc, html, Input, Output, State\n",
    "from dash import dash_table\n",
    "import dash_bootstrap_components as dbc\n",
    "from dash.exceptions import PreventUpdate\n",
    "import urllib.parse\n",
    "\n",
    "# Initialisation de l'application Dash avec des pages multiples\n",
    "app = dash.Dash(__name__, external_stylesheets=[dbc.themes.BOOTSTRAP], suppress_callback_exceptions=True)\n",
    "anomalies_with_BU = df.loc[X_test_result[X_test_result['anomaly'] == 1].index]\n",
    "# Identifier la BU la plus fréquente parmi les anomalies\n",
    "top_BU = anomalies_with_BU['BU'].mode()[0]\n",
    "\n",
    "# Filtrer uniquement les anomalies de cette BU\n",
    "filtered_anomalies = anomalies_with_BU[anomalies_with_BU['BU'] == top_BU]\n",
    "df['full_date'] = pd.to_datetime(df['full_date'], errors='coerce')\n",
    "# Colonnes numériques dans le DataFrame original\n",
    "numeric_cols_original = df.select_dtypes(include=['number']).columns.tolist()\n",
    "\n",
    "# Colonnes encodées dans X_test_result (souvent après transformation)\n",
    "encoded_cols = X_test_result.columns.tolist()\n",
    "\n",
    "# Colonnes numériques originales conservées (non transformées)\n",
    "numeric_cols = [col for col in numeric_cols_original if col in encoded_cols]\n",
    "# Récupérer les anomalies depuis le DataFrame original (non encodé)\n",
    "anomaly_indices = X_test_result[X_test_result['anomaly'] == 1].index\n",
    "anomalies = df.loc[anomaly_indices, ['full_date', 'BU', 'type_d_operation', 'violation_reason']]\n",
    "\n",
    "\n",
    "def calculate_metrics(df, gle):\n",
    "    metrics = {}\n",
    "    \n",
    "    # 1. Taux d'anomalies\n",
    "    metrics['anomaly_rate'] = df['anomaly'].mean()\n",
    "    \n",
    "    # 2. Coût estimé\n",
    "    metrics['estimated_cost'] = df['anomaly'].sum() * 10000  # Exemple de coût estimé par anomalie\n",
    "    \n",
    "    # 3. Segment à risque : BU non encodée\n",
    "    if 'BU' in gle.columns:\n",
    "        anomalies_idx = df[df['anomaly'] == 1].index\n",
    "        gle_anomalies = gle.loc[anomalies_idx]\n",
    "\n",
    "        bu_counts = gle_anomalies['BU'].value_counts()\n",
    "        if not bu_counts.empty:\n",
    "            top_bu = bu_counts.idxmax()\n",
    "            metrics['top_risk_BU'] = top_bu\n",
    "            metrics['BU_anomaly_rate'] = (gle.loc[gle['BU'] == top_bu].index.isin(anomalies_idx).sum()\n",
    "                                          / (gle['BU'] == top_bu).sum())\n",
    "        else:\n",
    "            metrics['top_risk_BU'] = \"Aucune anomalie\"\n",
    "            metrics['BU_anomaly_rate'] = 0\n",
    "    else:\n",
    "        metrics['top_risk_BU'] = \"Colonne BU manquante\"\n",
    "        metrics['BU_anomaly_rate'] = 0\n",
    "    \n",
    "    # 4. Dernière détection\n",
    "    \n",
    "    if 'full_date' in gle.columns:\n",
    "        try:\n",
    "            # On extrait les indices des anomalies dans df\n",
    "            anomaly_indices = df.index[df['anomaly'] == 1]\n",
    "\n",
    "            # On récupère les dates correspondantes dans gle\n",
    "            full_dates = gle.loc[anomaly_indices, 'full_date']\n",
    "\n",
    "            # Conversion si nécessaire\n",
    "            if not np.issubdtype(full_dates.dtype, np.datetime64):\n",
    "                full_dates = pd.to_datetime(full_dates, errors='coerce')\n",
    "\n",
    "            last_anomaly = full_dates.max()\n",
    "\n",
    "            if pd.notnull(last_anomaly):\n",
    "                metrics['last_anomaly_date'] = last_anomaly.strftime('%Y/%m/%d %H:%M:%S')\n",
    "            else:\n",
    "                metrics['last_anomaly_date'] = \"Date invalide\"\n",
    "        except Exception as e:\n",
    "            metrics['last_anomaly_date'] = f\"Erreur : {str(e)}\"\n",
    "\n",
    "\n",
    "    else:\n",
    "        metrics['last_anomaly_date'] = \"Colonne date manquante\"\n",
    "\n",
    "    return metrics\n",
    "X_test_result = X_test_result.copy()\n",
    "X_test_result['full_date'] = df.loc[X_test_result.index, 'full_date']\n",
    "\n",
    "# Convertir les dates en datetime\n",
    "X_test_result['full_date'] = pd.to_datetime(X_test_result['full_date'], errors='coerce')\n",
    "\n",
    "# Construire la figure\n",
    "fig_date = px.line(\n",
    "    X_test_result.groupby(X_test_result['full_date'].dt.date)['anomaly'].mean().reset_index(),\n",
    "    x='full_date',\n",
    "    y='anomaly',\n",
    "    labels={'full_date': 'Date', 'anomaly': 'Taux d\\'anomalies'},\n",
    "    title=\"Taux d'anomalies par jour\"\n",
    ")\n",
    "# X_test_result = \n",
    "# Calcul initial des métriques\n",
    "metrics = calculate_metrics(X_test_result,df)\n",
    "# Layout principal avec navigation\n",
    "app.layout = html.Div([\n",
    "    dcc.Location(id='url', refresh=False),\n",
    "    \n",
    "    # Barre de navigation\n",
    "    dbc.NavbarSimple(\n",
    "        children=[\n",
    "            dbc.NavItem(dbc.NavLink(\"Tableau de bord\", href=\"/\")),\n",
    "            dbc.NavItem(dbc.NavLink(\"Analyse des anomalies\", href=\"/anomaly-analysis\")),\n",
    "            dbc.NavItem(dbc.NavLink(\"Les KPIs\", href=\"/frequent-values\")),\n",
    "        ],\n",
    "        brand=\"Dashboard de Détection d'Anomalies\",\n",
    "        brand_href=\"/\",\n",
    "        color=\"danger\",\n",
    "        dark=True,\n",
    "        className=\"mb-4\"\n",
    "    ),\n",
    "    \n",
    "    # Contenu des pages\n",
    "    html.Div(id='page-content')\n",
    "])\n",
    "\n",
    "\n",
    "home_layout = dbc.Container([\n",
    "    dbc.Row([\n",
    "        dbc.Col(html.H1(\"Tableau de Bord\", className='text-center mb-4'), width=12)\n",
    "    ]),\n",
    "\n",
    "    dbc.Row([\n",
    "        # Colonne de gauche (Résumé + Répartition)\n",
    "        dbc.Col([\n",
    "            dbc.Card([\n",
    "                dbc.CardHeader(\"Résumé des Anomalies\"),\n",
    "                dbc.CardBody([\n",
    "                    html.H4(\"Anomalies détectées\", className=\"card-title\"),\n",
    "                    html.P(id='anomaly-count', className=\"display-4\"),\n",
    "                    html.P(f\"Sur {len(X_test)} observations testées\", className=\"card-text\")\n",
    "                ])\n",
    "            ], className='mb-4'),\n",
    "\n",
    "            dbc.Card([\n",
    "                dbc.CardHeader(\"Répartition des Anomalies\"),\n",
    "                dbc.CardBody([\n",
    "                    dcc.Graph(id='anomaly-distribution')\n",
    "                ])\n",
    "            ])\n",
    "        ], width=4),\n",
    "\n",
    "        # Colonne de droite (Tableau)\n",
    "        dbc.Col([\n",
    "            dbc.Card([\n",
    "                dbc.CardHeader(\"Détail des Anomalies\"),\n",
    "                dbc.CardBody([\n",
    "                    dash_table.DataTable(\n",
    "                        id='anomaly-table',\n",
    "                        columns=[{\"name\": i, \"id\": i} for i in anomalies.columns],\n",
    "                        data=anomalies.to_dict('records'),\n",
    "                        filter_action=\"native\",\n",
    "                        sort_action=\"native\",\n",
    "                        page_size=10,\n",
    "                        style_table={'overflowX': 'auto'}\n",
    "                    )\n",
    "                ])\n",
    "            ])\n",
    "        ], width=8)\n",
    "    ]),\n",
    "\n",
    "\n",
    "    # Nouvelle section pour la segmentation des anomalies\n",
    "    dbc.Row([\n",
    "        dbc.Col([\n",
    "            dbc.Card([\n",
    "                dbc.CardHeader(\"Segmentation des Anomalies\"),\n",
    "                dbc.CardBody([\n",
    "                    html.Label(\"Sélectionnez un attribut pour segmenter les anomalies:\"),\n",
    "                    dcc.Dropdown(\n",
    "                        id='segmentation-attribute',\n",
    "                        options=[\n",
    "                            {'label': 'Âge du souscripteur', 'value': 'age_sub'},\n",
    "                            {'label': 'Business Unit', 'value': 'BU'},\n",
    "                            {'label': 'Wilaya', 'value': 'Province'},\n",
    "                            {'label': 'Jour de la semaine', 'value': 'lib_jour'},\n",
    "                            {'label': 'Mois', 'value': 'full_date'},  # Assurez-vous que cette colonne existe\n",
    "                        ],\n",
    "                        value='age_sub',\n",
    "                        clearable=False\n",
    "                    ),\n",
    "                    dcc.Graph(id='anomaly-segmentation-plot')\n",
    "                ])\n",
    "            ], className='mt-4')\n",
    "        ], width=12)\n",
    "    ]),\n",
    "    \n",
    "    # Bouton pour aller à l'analyse détaillée\n",
    "    dbc.Row([\n",
    "        dbc.Col(\n",
    "            dbc.Button(\n",
    "                \"Voir l'analyse détaillée des anomalies\", \n",
    "                color=\"danger\", \n",
    "                href=\"/anomaly-analysis\",\n",
    "                className=\"mt-4\"\n",
    "            ),\n",
    "            width=12, className=\"text-center\"\n",
    "        )\n",
    "    ])\n",
    "], fluid=True)\n",
    "# Layout de la page d'analyse des anomalies\n",
    "anomaly_analysis_layout = dbc.Container([\n",
    "    dbc.Row([\n",
    "        dbc.Col(html.H1(\"Analyse Détailée des Anomalies\", className='text-center mb-4'), width=12)\n",
    "    ]),\n",
    "    \n",
    "    # Analyse des Features Importantes\n",
    "    dbc.Row([\n",
    "        dbc.Col([\n",
    "            dbc.Card([\n",
    "                dbc.CardHeader(\"Contribution des Variables aux Anomalies\"),\n",
    "                dbc.CardBody([\n",
    "                    dcc.Graph(id='feature-importance')\n",
    "                ])\n",
    "            ])\n",
    "        ], width=12)\n",
    "    ]),\n",
    "    \n",
    "    # Détails des Anomalies\n",
    "    dbc.Row([\n",
    "        dbc.Col([\n",
    "            dbc.Card([\n",
    "                dbc.CardHeader(\"Détails des Anomalies Détectées\"),\n",
    "                dbc.CardBody([\n",
    "                    html.Label(\"Sélectionnez une anomalie pour plus de détails:\"),\n",
    "                    dcc.Dropdown(\n",
    "                        id='anomaly-selector',\n",
    "                        options=[{'label': f\"Anomalie {i+1}\", 'value': idx} \n",
    "                                for i, idx in enumerate(anomaly_explainer.anomalies_idx)],\n",
    "                        value=None\n",
    "                    ),\n",
    "                    html.Div(id='anomaly-details', className='mt-3')\n",
    "                ])\n",
    "            ])\n",
    "        ], width=12)\n",
    "    ], className='mt-4'),\n",
    "    \n",
    "    dbc.Row([\n",
    "        dbc.Col([\n",
    "            dbc.Card([\n",
    "                dbc.CardHeader(\"Analyse Comparative\"),\n",
    "                dbc.CardBody([\n",
    "                    dbc.Row([\n",
    "                        dbc.Col([\n",
    "                            html.Label(\"Variable X:\"),\n",
    "                            dcc.Dropdown(\n",
    "                                id='scatter-x',\n",
    "                                options=[{'label': col, 'value': col} for col in numeric_cols],\n",
    "                                value=numeric_cols[0]\n",
    "                            )\n",
    "                        ], md=6),\n",
    "                        dbc.Col([\n",
    "                            html.Label(\"Variable Y:\"),\n",
    "                            dcc.Dropdown(\n",
    "                                id='scatter-y',\n",
    "                                options=[{'label': col, 'value': col} for col in numeric_cols],\n",
    "                                value=numeric_cols[1]\n",
    "                            )\n",
    "                        ], md=6)\n",
    "                    ]),\n",
    "                    dcc.Graph(id='comparative-scatter')\n",
    "                ])\n",
    "            ])\n",
    "        ])\n",
    "    ]),\n",
    "    # Bouton de retour\n",
    "    dbc.Row([\n",
    "        dbc.Col(\n",
    "            dbc.Button(\n",
    "                \"Retour au tableau de bord\", \n",
    "                color=\"secondary\", \n",
    "                href=\"/\",\n",
    "                className=\"mt-4\"\n",
    "            ),\n",
    "            width=12, className=\"text-center\"\n",
    "        )\n",
    "    ])\n",
    "], fluid=True)\n",
    "anomalies = X_test_result[X_test_result['anomaly'] == 1]\n",
    "# Layout de la page des valeurs fréquentes\n",
    "frequent_values_layout = dbc.Container([\n",
    "    \n",
    "    dbc.Row([\n",
    "        dbc.Col(html.H1(\"KPIs\", className='text-center my-4'), width=12)\n",
    "    ]),\n",
    "    \n",
    "    # Cartes de métriques\n",
    "    dbc.Row([\n",
    "        dbc.Col(\n",
    "            dbc.Card([\n",
    "                dbc.CardHeader(\"Taux d'Anomalies\"),\n",
    "                dbc.CardBody([\n",
    "                    html.H4(f\"{metrics['anomaly_rate']:.2%}\", className=\"card-title text-primary\"),\n",
    "                    html.Small(f\"Sur {len(X_test_result)} observations\", className=\"text-muted\"),\n",
    "                    dbc.Progress(\n",
    "                        value=metrics['anomaly_rate']*100, \n",
    "                        max=100, \n",
    "                        color=\"primary\", \n",
    "                        striped=True,\n",
    "                        className=\"mt-2\"\n",
    "                    )\n",
    "                ])\n",
    "            ]), md=3\n",
    "        ),\n",
    "        dbc.Col(\n",
    "            dbc.Card([\n",
    "                dbc.CardHeader(\"Coût Estimé\"),\n",
    "                dbc.CardBody([\n",
    "                    html.H4(f\"{metrics['estimated_cost']:,.0f} DZD\", className=\"card-title text-warning\"),\n",
    "                    # html.Small(f\"Pour {df['anomaly'].sum()} anomalies\", className=\"text-muted\")\n",
    "                ])\n",
    "            ]), md=3\n",
    "        ),\n",
    "        dbc.Col(\n",
    "            dbc.Card([\n",
    "                dbc.CardHeader(\"BU la Plus à Risque\"),\n",
    "                dbc.CardBody([\n",
    "                    html.H4(metrics['top_risk_BU'], className=\"card-title text-info\"),\n",
    "                    html.Small(f\"Taux: {metrics['BU_anomaly_rate']:.2%}\", className=\"text-muted\")\n",
    "                ])\n",
    "            ]), md=3\n",
    "        ),\n",
    "        dbc.Col(\n",
    "            dbc.Card([\n",
    "                dbc.CardHeader(\"Dernière Anomalie\"),\n",
    "                dbc.CardBody([\n",
    "                    html.H4(metrics['last_anomaly_date'], className=\"card-title\"),\n",
    "                    html.Small(\"Détectée le\", className=\"text-muted\")\n",
    "                ])\n",
    "            ]), md=3\n",
    "        )\n",
    "    ], className=\"mb-4\"),\n",
    "    \n",
    "    # Graphiques\n",
    "    dbc.Row([\n",
    "        dbc.Col([\n",
    "            dbc.Card([\n",
    "                dbc.CardHeader(\"Évolution Temporelle des Anomalies\"),\n",
    "                dbc.CardBody([\n",
    "                    dcc.Graph(figure=fig_date)\n",
    "                ])\n",
    "            ])\n",
    "        ], md=6),\n",
    "        dbc.Col([\n",
    "            html.Div([\n",
    "                dbc.Label(\"Sélectionnez une BU :\"),\n",
    "                dcc.Dropdown(\n",
    "                    id='bu-selector',\n",
    "                    options=[{'label': bu, 'value': bu} for bu in df['BU'].dropna().unique()],\n",
    "                    value=df['BU'].mode()[0],  # valeur par défaut\n",
    "                    clearable=False\n",
    "                )\n",
    "            ]),\n",
    "\n",
    "            dbc.Card([\n",
    "                dbc.CardHeader(\"Répartition des anomalies par utilisateur\"),\n",
    "                dbc.CardBody([\n",
    "                    dcc.Graph(id='dok-usr-pie')\n",
    "                ])\n",
    "            ])\n",
    "\n",
    "        ], md=6)\n",
    "\n",
    "    ]),\n",
    "    \n",
    "    # Intervalle de rafraîchissement (optionnel)\n",
    "    dcc.Interval(id='refresh-interval', interval=60*1000, n_intervals=0)\n",
    "])# Callback pour changer de page\n",
    "@app.callback(\n",
    "    Output('page-content', 'children'),\n",
    "    [Input('url', 'pathname')]\n",
    ")\n",
    "def display_page(pathname):\n",
    "    if pathname == '/':\n",
    "        return home_layout\n",
    "    elif pathname == '/anomaly-analysis':\n",
    "        return anomaly_analysis_layout\n",
    "    elif pathname == '/frequent-values':\n",
    "        return frequent_values_layout\n",
    "    else:\n",
    "        return home_layout  # Page par défaut\n",
    "\n",
    "# Callbacks pour l'interactivité\n",
    "\n",
    "@app.callback(\n",
    "    Output('anomaly-count', 'children'),\n",
    "    Input('anomaly-distribution', 'figure')\n",
    ")\n",
    "def update_anomaly_count(_):\n",
    "    return f\"{sum(predictions)}\"\n",
    "\n",
    "@app.callback(\n",
    "    Output('anomaly-distribution', 'figure'),\n",
    "    Input('anomaly-distribution', 'id')\n",
    ")\n",
    "def update_anomaly_distribution(_):\n",
    "    fig = px.pie(\n",
    "        names=['Normales', 'Anomalies'],\n",
    "        values=[len(predictions)-sum(predictions), sum(predictions)],\n",
    "        hole=0.4,\n",
    "        color_discrete_sequence=['#4da7ff', '#ff8700']\n",
    "    )\n",
    "    fig.update_layout(showlegend=False)\n",
    "    return fig\n",
    "\n",
    "@app.callback(\n",
    "    Output('anomaly-segmentation-plot', 'figure'),\n",
    "    Input('segmentation-attribute', 'value'),\n",
    "    prevent_initial_call=True\n",
    ")\n",
    "def update_segmentation_plot(attribute):\n",
    "    # Récupérer les indices des anomalies détectées\n",
    "    anomalies_idx = X_test_result[X_test_result['anomaly'] == 1].index\n",
    "\n",
    "    # Accéder aux valeurs originales depuis le DataFrame 'gle'\n",
    "    anomalies_original = df.loc[anomalies_idx]\n",
    "\n",
    "    if attribute == 'full_date':\n",
    "        anomalies_original['mois'] = pd.to_datetime(anomalies_original[attribute], errors='coerce').dt.month_name()\n",
    "        segment_counts = anomalies_original['mois'].value_counts().reset_index()\n",
    "        segment_counts.columns = ['mois', 'count']\n",
    "        fig = px.bar(\n",
    "            segment_counts,\n",
    "            x='mois',\n",
    "            y='count',\n",
    "            title=\"Anomalies par mois\",\n",
    "            labels={'mois': 'Mois', 'count': \"Nombre d'anomalies\"}\n",
    "        )\n",
    "    else:\n",
    "        column_data = anomalies_original[attribute]\n",
    "        segment_counts = column_data.value_counts().reset_index()\n",
    "        segment_counts.columns = [attribute, 'count']\n",
    "\n",
    "        # Trop de catégories → limiter à 20\n",
    "        if len(segment_counts) > 20:\n",
    "            segment_counts = segment_counts.nlargest(20, 'count')\n",
    "\n",
    "        if pd.api.types.is_numeric_dtype(column_data):\n",
    "            fig = px.histogram(\n",
    "                column_data,\n",
    "                x=attribute,\n",
    "                title=f\"Distribution des anomalies par {attribute}\",\n",
    "                nbins=20\n",
    "            )\n",
    "        else:\n",
    "            fig = px.bar(\n",
    "                segment_counts,\n",
    "                x=attribute,\n",
    "                y='count',\n",
    "                title=f\"Anomalies par {attribute}\",\n",
    "                labels={attribute: attribute, 'count': \"Nombre d'anomalies\"}\n",
    "            )\n",
    "\n",
    "    fig.update_layout(\n",
    "        xaxis_title=attribute,\n",
    "        yaxis_title=\"Nombre d'anomalies\",\n",
    "        hovermode='x'\n",
    "    )\n",
    "\n",
    "    return fig\n",
    "\n",
    "\n",
    "@app.callback(\n",
    "    Output('feature-importance', 'figure'),\n",
    "    Input('feature-importance', 'id')\n",
    ")\n",
    "def update_feature_importance(_):\n",
    "    # Calcul de l'importance des features (exemple avec les erreurs de reconstruction)\n",
    "    anomalies = X_test_result[X_test_result['anomaly'] == 1]\n",
    "    \n",
    "    # Calcul des écarts moyens par rapport à la médiane\n",
    "    feature_scores = {}\n",
    "    for col in selected_final:\n",
    "        if np.issubdtype(X_test[col].dtype, np.number):\n",
    "            median = X_train[col].median()\n",
    "            iqr = X_train[col].quantile(0.75) - X_train[col].quantile(0.25)\n",
    "            score = np.mean(np.abs(anomalies[col] - median) / (iqr + 1e-8))\n",
    "            feature_scores[col] = score\n",
    "    \n",
    "    # Tri des features par importance\n",
    "    sorted_features = sorted(feature_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    fig = px.bar(\n",
    "        x=[f[0] for f in sorted_features],\n",
    "        y=[f[1] for f in sorted_features],\n",
    "        labels={'x': 'Variable', 'y': 'Score d\\'importance'},\n",
    "        title=\"Contribution des Variables aux Anomalies\"\n",
    "    )\n",
    "    \n",
    "    return fig\n",
    "X_preprocessed= preprocess_unsupervised(df[selected_final])\n",
    "# Callback modifié\n",
    "@app.callback(\n",
    "    Output('anomaly-details', 'children'),\n",
    "    Input('anomaly-selector', 'value'),\n",
    "    prevent_initial_call=True\n",
    ")\n",
    "\n",
    "\n",
    "def update_anomaly_details(selected_index):\n",
    "        if selected_index is None:\n",
    "            return dbc.Alert(\"Sélectionnez une anomalie pour voir les détails\", color=\"info\")\n",
    "        \n",
    "        # Obtenir toutes les explications\n",
    "        explanations = anomaly_explainer.explain_anomalies()\n",
    "        \n",
    "        # Trouver l'explication correspondant à l'index sélectionné\n",
    "        explanation = next((exp for exp in explanations if exp['index'] == selected_index), None)\n",
    "    \n",
    "        if not explanation:\n",
    "            return dbc.Alert(\"Impossible d'expliquer cette anomalie\", color=\"warning\")\n",
    "        \n",
    "        # Gauge du score de suspicion\n",
    "        suspicion_score = explanation['suspicion_score'] * 10\n",
    "        features = explanation['top_contributors']\n",
    "        suspicion_gauge = dcc.Graph(\n",
    "            figure={\n",
    "                'data': [{\n",
    "                    'type': 'indicator',\n",
    "                    'mode': 'gauge+number',\n",
    "                    'value': suspicion_score,\n",
    "                    'title': {'text': \"Score de Suspicion\"},\n",
    "                    'gauge': {\n",
    "                        'axis': {'range': [0, 10]},\n",
    "                        'steps': [\n",
    "                            {'range': [0, 4], 'color': \"lightgreen\"},\n",
    "                            {'range': [4, 7], 'color': \"orange\"},\n",
    "                            {'range': [7, 10], 'color': \"red\"}\n",
    "                        ]\n",
    "                    }\n",
    "                }],\n",
    "                'layout': {'height': 200, 'margin': {'t': 0, 'b': 0}}\n",
    "            },\n",
    "            className='mb-4'\n",
    "        )\n",
    "\n",
    "        # Graphique radar\n",
    "        features = explanation.get('top_contributors', [])\n",
    "        deviations = [explanation['deviation_values'].get(f, 0) for f in features]\n",
    "        \n",
    "        radar_chart = dcc.Graph(\n",
    "            figure={\n",
    "                'data': [{\n",
    "                    'type': 'scatterpolar',\n",
    "                    'r': deviations + [deviations[0]] if deviations else [],\n",
    "                    'theta': features + [features[0]] if features else [],\n",
    "                    'fill': 'toself',\n",
    "                    'name': 'Déviation'\n",
    "                }],\n",
    "                'layout': {\n",
    "                    'polar': {'radialaxis': {'visible': True}},\n",
    "                    'height': 300,\n",
    "                    'margin': {'t': 30, 'b': 30}\n",
    "                }\n",
    "            },\n",
    "            className='mb-4'\n",
    "        )\n",
    "\n",
    "        # Cartes de détails\n",
    "        var_cards = []\n",
    "        for feature in features:\n",
    "            true_value = explanation['real_values'].get(feature, \"N/A\")\n",
    "            deviation = explanation['deviation_values'].get(feature, 0)\n",
    "            bar_color = \"danger\" if deviation > 0 else \"info\"\n",
    "\n",
    "            var_cards.append(\n",
    "                dbc.Card([\n",
    "                    dbc.CardHeader(f\"Variable : {feature}\"),\n",
    "                    dbc.CardBody([\n",
    "                        html.H5(f\"{true_value}\", className=\"card-title\"),\n",
    "                        html.P(\"Écart par rapport à la moyenne locale :\"),\n",
    "                        dbc.Progress(\n",
    "                            value=min(abs(deviation) * 10, 10),\n",
    "                            max=10,\n",
    "                            color=bar_color,\n",
    "                            label=f\"{deviation:.2f}\",\n",
    "                            className=\"mb-2\"\n",
    "                        ),\n",
    "                        dbc.Badge(\n",
    "                            \"Au-dessus\" if deviation > 0 else \"En-dessous\",\n",
    "                            color=bar_color,\n",
    "                            className=\"me-1\"\n",
    "                        )\n",
    "                    ])\n",
    "                ], className=\"mb-3\")\n",
    "            )\n",
    "\n",
    "        return html.Div([\n",
    "            dbc.Row([\n",
    "                dbc.Col(suspicion_gauge, width=6),\n",
    "                dbc.Col(radar_chart, width=6)\n",
    "            ]),\n",
    "            html.Hr(),\n",
    "            html.H4(\"Détails des variables\", className=\"mt-3\"),\n",
    "            dbc.Row([dbc.Col(card) for card in var_cards])\n",
    "        ])\n",
    "        \n",
    "\n",
    "@app.callback(\n",
    "    Output('download-link', 'href'),\n",
    "    Input('download-link', 'n_clicks')\n",
    ")\n",
    "def update_download_link(_):\n",
    "    anomalies = X_test_result[X_test_result['anomaly'] == 1]\n",
    "    csv_string = anomalies.to_csv(index=False, encoding='utf-8')\n",
    "    csv_string = \"data:text/csv;charset=utf-8,\" + urllib.parse.quote(csv_string)\n",
    "    return csv_string\n",
    "@app.callback(\n",
    "    Output('frequent-values-plot', 'figure'),\n",
    "    [Input('freq-column-selector', 'value'),\n",
    "     Input('top-n-slider', 'value')],\n",
    "    prevent_initial_call=True\n",
    ")\n",
    "def update_frequent_values_plot(selected_column, top_n):\n",
    "    # Récupérer uniquement les lignes identifiées comme anomalies\n",
    "    anomalies = X_test_result[X_test_result['anomaly'] == 1]\n",
    "\n",
    "    # Appeler la fonction avec le DataFrame original brut\n",
    "    return create_top_frequent_values_plot(\n",
    "        anomalies, \n",
    "        selected_column, \n",
    "        top_n, \n",
    "        df_original=df  # Assurez-vous que `df` est le DataFrame original non prétraité\n",
    "    )\n",
    "from dash.dependencies import Input, Output\n",
    "from datetime import datetime\n",
    "\n",
    "@app.callback(\n",
    "    [Output('anomaly-rate-card', 'children'),\n",
    "     Output('cost-card', 'children'),\n",
    "     Output('risk-card', 'children'),\n",
    "     Output('last-detection-card', 'children')],\n",
    "    Input('refresh-interval', 'n_intervals')\n",
    ")\n",
    "def update_metrics(n):\n",
    "    # Recalculer les métriques (ici on utilise les mêmes données)\n",
    "    metrics = calculate_metrics(X_test_result)\n",
    "    \n",
    "    return [\n",
    "        # Carte 1\n",
    "        [\n",
    "            html.H4(f\"{metrics['anomaly_rate']:.2%}\", className=\"card-title text-primary\"),\n",
    "            html.Small(f\"Sur {len(X_test_result)} observations\", className=\"text-muted\"),\n",
    "            dbc.Progress(value=metrics['anomaly_rate']*100, max=100, color=\"primary\", striped=True)\n",
    "        ],\n",
    "        # Carte 2\n",
    "        [\n",
    "            html.H4(f\"{metrics['estimated_cost']:,.0f} DZD\", className=\"card-title text-warning\"),\n",
    "            html.Small(f\"Pour {df['anomaly'].sum()} anomalies\", className=\"text-muted\")\n",
    "        ],\n",
    "        # Carte 3\n",
    "        [\n",
    "            html.H4(metrics['top_risk_BU'], className=\"card-title text-info\"),\n",
    "            html.Small(f\"Taux: {metrics['BU_anomaly_rate']:.2%}\", className=\"text-muted\")\n",
    "        ],\n",
    "        # Carte 4\n",
    "        [\n",
    "            html.H4(metrics['last_anomaly_date'], className=\"card-title\"),\n",
    "            html.Small(\"Détectée le\", className=\"text-muted\")\n",
    "        ]\n",
    "    ]\n",
    "@app.callback(\n",
    "    Output('dok-usr-pie', 'figure'),\n",
    "    Input('bu-selector', 'value')\n",
    ")\n",
    "def update_pie_chart(selected_bu):\n",
    "    anomalies_with_BU = df.loc[X_test_result[X_test_result['anomaly'] == 1].index].copy()\n",
    "    filtered = anomalies_with_BU[anomalies_with_BU['BU'] == selected_bu]\n",
    "    fig = px.pie(\n",
    "        filtered,\n",
    "        names='DOK_SCN_USR',\n",
    "        title=f\"Anomalies par utilisateur pour la BU {selected_bu}\",\n",
    "        hole=0.4\n",
    "    )\n",
    "    return fig\n",
    "@app.callback(\n",
    "    Output('comparative-scatter', 'figure'),\n",
    "    [Input('scatter-x', 'value'),\n",
    "     Input('scatter-y', 'value')]\n",
    ")\n",
    "def update_scatter(x_col, y_col):\n",
    "    fig = px.scatter(\n",
    "        X_test_result,\n",
    "        x=x_col,\n",
    "        y=y_col,\n",
    "        color='anomaly',\n",
    "        marginal_x=\"box\",\n",
    "        marginal_y=\"violin\"\n",
    "    )\n",
    "    return fig\n",
    "\n",
    "import webbrowser\n",
    "from threading import Timer\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Ouvre automatiquement dans un navigateur\n",
    "    Timer(1, lambda: webbrowser.open_new(\"http://127.0.0.1:8050/\")).start()\n",
    "    app.run(debug=True, use_reloader=False)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b224d8e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:8050/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x28e2c68dab0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import dash\n",
    "from dash import dcc, html, Input, Output, State\n",
    "from dash import dash_table\n",
    "import dash_bootstrap_components as dbc\n",
    "from dash.exceptions import PreventUpdate\n",
    "import urllib.parse\n",
    "import webbrowser\n",
    "from threading import Timer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "# Initialisation de l'application Dash avec des pages multiples\n",
    "app = dash.Dash(\n",
    "    __name__, \n",
    "    external_stylesheets=[dbc.themes.BOOTSTRAP], \n",
    "    suppress_callback_exceptions=True\n",
    ")\n",
    "\n",
    "# ==============================================\n",
    "# DATA PREPARATION\n",
    "# ==============================================\n",
    "\n",
    "# Assuming df and X_test_result are defined elsewhere\n",
    "# For this example, I'll create mock data structures\n",
    "df = pd.DataFrame({\n",
    "    'full_date': pd.date_range('2023-01-01', periods=100),\n",
    "    'BU': np.random.choice(['BU1', 'BU2', 'BU3'], 100),\n",
    "    'type_d_operation': np.random.choice(['TypeA', 'TypeB', 'TypeC'], 100),\n",
    "    'violation_reason': np.random.choice(['Reason1', 'Reason2', 'Reason3'], 100),\n",
    "    'age_sub': np.random.randint(18, 70, 100),\n",
    "    'Province': np.random.choice(['Prov1', 'Prov2', 'Prov3'], 100),\n",
    "    'lib_jour': np.random.choice(['Mon', 'Tue', 'Wed'], 100),\n",
    "    'DOK_SCN_USR': np.random.choice(['User1', 'User2', 'User3'], 100),\n",
    "    'anomaly': np.random.choice([0, 1], 100, p=[0.9, 0.1])\n",
    "})\n",
    "\n",
    "X_test_result = df.copy()\n",
    "selected_final = ['age_sub', 'BU', 'Province', 'lib_jour']\n",
    "X_train = df.sample(frac=0.8)\n",
    "X_test = df.drop(X_train.index)\n",
    "\n",
    "# Mock anomaly explainer\n",
    "class MockAnomalyExplainer:\n",
    "    def __init__(self):\n",
    "        self.anomalies_idx = X_test_result[X_test_result['anomaly'] == 1].index.tolist()\n",
    "    \n",
    "    def explain_anomalies(self):\n",
    "        explanations = []\n",
    "        for idx in self.anomalies_idx:\n",
    "            explanations.append({\n",
    "                'index': idx,\n",
    "                'suspicion_score': np.random.random(),\n",
    "                'top_contributors': np.random.choice(selected_final, 3).tolist(),\n",
    "                'deviation_values': {col: np.random.normal() for col in selected_final},\n",
    "                'real_values': {col: X_test_result.loc[idx, col] for col in selected_final}\n",
    "            })\n",
    "        return explanations\n",
    "\n",
    "anomaly_explainer = MockAnomalyExplainer()\n",
    "\n",
    "# ==============================================\n",
    "# UTILITY FUNCTIONS\n",
    "# ==============================================\n",
    "\n",
    "def calculate_metrics(df, gle):\n",
    "    metrics = {}\n",
    "    \n",
    "    # 1. Taux d'anomalies\n",
    "    metrics['anomaly_rate'] = df['anomaly'].mean()\n",
    "    \n",
    "    # 2. Coût estimé\n",
    "    metrics['estimated_cost'] = df['anomaly'].sum() * 10000  # Exemple de coût estimé par anomalie\n",
    "    \n",
    "    # 3. Segment à risque : BU non encodée\n",
    "    if 'BU' in gle.columns:\n",
    "        anomalies_idx = df[df['anomaly'] == 1].index\n",
    "        gle_anomalies = gle.loc[anomalies_idx]\n",
    "\n",
    "        bu_counts = gle_anomalies['BU'].value_counts()\n",
    "        if not bu_counts.empty:\n",
    "            top_bu = bu_counts.idxmax()\n",
    "            metrics['top_risk_BU'] = top_bu\n",
    "            metrics['BU_anomaly_rate'] = (gle.loc[gle['BU'] == top_bu].index.isin(anomalies_idx).sum() / \n",
    "                                          (gle['BU'] == top_bu).sum())\n",
    "        else:\n",
    "            metrics['top_risk_BU'] = \"Aucune anomalie\"\n",
    "            metrics['BU_anomaly_rate'] = 0\n",
    "    else:\n",
    "        metrics['top_risk_BU'] = \"Colonne BU manquante\"\n",
    "        metrics['BU_anomaly_rate'] = 0\n",
    "    \n",
    "    # 4. Dernière détection\n",
    "    if 'full_date' in gle.columns:\n",
    "        try:\n",
    "            anomaly_indices = df.index[df['anomaly'] == 1]\n",
    "            full_dates = gle.loc[anomaly_indices, 'full_date']\n",
    "            \n",
    "            if not np.issubdtype(full_dates.dtype, np.datetime64):\n",
    "                full_dates = pd.to_datetime(full_dates, errors='coerce')\n",
    "\n",
    "            last_anomaly = full_dates.max()\n",
    "            metrics['last_anomaly_date'] = last_anomaly.strftime('%Y/%m/%d %H:%M:%S') if pd.notnull(last_anomaly) else \"Date invalide\"\n",
    "        except Exception as e:\n",
    "            metrics['last_anomaly_date'] = f\"Erreur : {str(e)}\"\n",
    "    else:\n",
    "        metrics['last_anomaly_date'] = \"Colonne date manquante\"\n",
    "\n",
    "    return metrics\n",
    "\n",
    "def create_top_frequent_values_plot(df, column, top_n, df_original=None):\n",
    "    # Implementation would go here\n",
    "    pass\n",
    "\n",
    "# ==============================================\n",
    "# LAYOUT COMPONENTS\n",
    "# ==============================================\n",
    "\n",
    "def create_navbar():\n",
    "    return dbc.NavbarSimple(\n",
    "        children=[\n",
    "            dbc.NavItem(dbc.NavLink(\"Tableau de bord\", href=\"/\")),\n",
    "            dbc.NavItem(dbc.NavLink(\"Analyse des anomalies\", href=\"/anomaly-analysis\")),\n",
    "            dbc.NavItem(dbc.NavLink(\"Les KPIs\", href=\"/frequent-values\")),\n",
    "        ],\n",
    "        brand=\"Dashboard de Détection d'Anomalies\",\n",
    "        brand_href=\"/\",\n",
    "        color=\"danger\",\n",
    "        dark=True,\n",
    "        className=\"mb-4\"\n",
    "    )\n",
    "\n",
    "def create_home_layout():\n",
    "    anomalies = df.loc[X_test_result[X_test_result['anomaly'] == 1].index]\n",
    "    metrics = calculate_metrics(X_test_result, df)\n",
    "    \n",
    "    return dbc.Container([\n",
    "        dbc.Row([\n",
    "            dbc.Col(html.H1(\"Tableau de Bord\", className='text-center mb-4'), width=12)\n",
    "        ]),\n",
    "\n",
    "        dbc.Row([\n",
    "            dbc.Col([\n",
    "                dbc.Card([\n",
    "                    dbc.CardHeader(\"Résumé des Anomalies\"),\n",
    "                    dbc.CardBody([\n",
    "                        html.H4(\"Anomalies détectées\", className=\"card-title\"),\n",
    "                        html.P(f\"{sum(X_test_result['anomaly'])}\", className=\"display-4\"),\n",
    "                        html.P(f\"Sur {len(X_test_result)} observations testées\", className=\"card-text\")\n",
    "                    ])\n",
    "                ], className='mb-4'),\n",
    "\n",
    "                dbc.Card([\n",
    "                    dbc.CardHeader(\"Répartition des Anomalies\"),\n",
    "                    dbc.CardBody([\n",
    "                        dcc.Graph(\n",
    "                            figure=px.pie(\n",
    "                                names=['Normales', 'Anomalies'],\n",
    "                                values=[len(X_test_result)-sum(X_test_result['anomaly']), sum(X_test_result['anomaly'])],\n",
    "                                hole=0.4,\n",
    "                                color_discrete_sequence=['#4da7ff', '#ff8700']\n",
    "                            ).update_layout(showlegend=False)\n",
    "                        )\n",
    "                    ])\n",
    "                ])\n",
    "            ], width=4),\n",
    "\n",
    "            dbc.Col([\n",
    "                dbc.Card([\n",
    "                    dbc.CardHeader(\"Détail des Anomalies\"),\n",
    "                    dbc.CardBody([\n",
    "                        dash_table.DataTable(\n",
    "                            id='anomaly-table',\n",
    "                            columns=[{\"name\": i, \"id\": i} for i in anomalies.columns],\n",
    "                            data=anomalies.to_dict('records'),\n",
    "                            filter_action=\"native\",\n",
    "                            sort_action=\"native\",\n",
    "                            page_size=10,\n",
    "                            style_table={'overflowX': 'auto'}\n",
    "                        )\n",
    "                    ])\n",
    "                ])\n",
    "            ], width=8)\n",
    "        ]),\n",
    "\n",
    "        dbc.Row([\n",
    "            dbc.Col([\n",
    "                dbc.Card([\n",
    "                    dbc.CardHeader(\"Segmentation des Anomalies\"),\n",
    "                    dbc.CardBody([\n",
    "                        html.Label(\"Sélectionnez un attribut pour segmenter les anomalies:\"),\n",
    "                        dcc.Dropdown(\n",
    "                            id='segmentation-attribute',\n",
    "                            options=[\n",
    "                                {'label': 'Âge du souscripteur', 'value': 'age_sub'},\n",
    "                                {'label': 'Business Unit', 'value': 'BU'},\n",
    "                                {'label': 'Wilaya', 'value': 'Province'},\n",
    "                                {'label': 'Jour de la semaine', 'value': 'lib_jour'},\n",
    "                                {'label': 'Mois', 'value': 'full_date'},\n",
    "                            ],\n",
    "                            value='age_sub',\n",
    "                            clearable=False\n",
    "                        ),\n",
    "                        dcc.Graph(id='anomaly-segmentation-plot')\n",
    "                    ])\n",
    "                ], className='mt-4')\n",
    "            ], width=12)\n",
    "        ]),\n",
    "        \n",
    "        dbc.Row([\n",
    "            dbc.Col(\n",
    "                dbc.Button(\n",
    "                    \"Voir l'analyse détaillée des anomalies\", \n",
    "                    color=\"danger\", \n",
    "                    href=\"/anomaly-analysis\",\n",
    "                    className=\"mt-4\"\n",
    "                ),\n",
    "                width=12, className=\"text-center\"\n",
    "            )\n",
    "        ])\n",
    "    ], fluid=True)\n",
    "\n",
    "def create_anomaly_analysis_layout():\n",
    "    return dbc.Container([\n",
    "        dbc.Row([\n",
    "            dbc.Col(html.H1(\"Analyse Détailée des Anomalies\", className='text-center mb-4'), width=12)\n",
    "        ]),\n",
    "        \n",
    "        dbc.Row([\n",
    "            dbc.Col([\n",
    "                dbc.Card([\n",
    "                    dbc.CardHeader(\"Contribution des Variables aux Anomalies\"),\n",
    "                    dbc.CardBody([\n",
    "                        dcc.Graph(id='feature-importance')\n",
    "                    ])\n",
    "                ])\n",
    "            ], width=12)\n",
    "        ]),\n",
    "        \n",
    "        dbc.Row([\n",
    "            dbc.Col([\n",
    "                dbc.Card([\n",
    "                    dbc.CardHeader(\"Détails des Anomalies Détectées\"),\n",
    "                    dbc.CardBody([\n",
    "                        html.Label(\"Sélectionnez une anomalie pour plus de détails:\"),\n",
    "                        dcc.Dropdown(\n",
    "                            id='anomaly-selector',\n",
    "                            options=[{'label': f\"Anomalie {i+1}\", 'value': idx} \n",
    "                                    for i, idx in enumerate(anomaly_explainer.anomalies_idx)],\n",
    "                            value=None\n",
    "                        ),\n",
    "                        html.Div(id='anomaly-details', className='mt-3')\n",
    "                    ])\n",
    "                ])\n",
    "            ], width=12)\n",
    "        ], className='mt-4'),\n",
    "        \n",
    "        dbc.Row([\n",
    "            dbc.Col([\n",
    "                dbc.Card([\n",
    "                    dbc.CardHeader(\"Analyse Comparative\"),\n",
    "                    dbc.CardBody([\n",
    "                        dbc.Row([\n",
    "                            dbc.Col([\n",
    "                                html.Label(\"Variable X:\"),\n",
    "                                dcc.Dropdown(\n",
    "                                    id='scatter-x',\n",
    "                                    options=[{'label': col, 'value': col} for col in selected_final],\n",
    "                                    value=selected_final[0]\n",
    "                                )\n",
    "                            ], md=6),\n",
    "                            dbc.Col([\n",
    "                                html.Label(\"Variable Y:\"),\n",
    "                                dcc.Dropdown(\n",
    "                                    id='scatter-y',\n",
    "                                    options=[{'label': col, 'value': col} for col in selected_final],\n",
    "                                    value=selected_final[1]\n",
    "                                )\n",
    "                            ], md=6)\n",
    "                        ]),\n",
    "                        dcc.Graph(id='comparative-scatter')\n",
    "                    ])\n",
    "                ])\n",
    "            ])\n",
    "        ]),\n",
    "        \n",
    "        dbc.Row([\n",
    "            dbc.Col(\n",
    "                dbc.Button(\n",
    "                    \"Retour au tableau de bord\", \n",
    "                    color=\"secondary\", \n",
    "                    href=\"/\",\n",
    "                    className=\"mt-4\"\n",
    "                ),\n",
    "                width=12, className=\"text-center\"\n",
    "            )\n",
    "        ])\n",
    "    ], fluid=True)\n",
    "\n",
    "def create_frequent_values_layout():\n",
    "    metrics = calculate_metrics(X_test_result, df)\n",
    "    fig_date = px.line(\n",
    "        X_test_result.groupby(X_test_result['full_date'].dt.date)['anomaly'].mean().reset_index(),\n",
    "        x='full_date',\n",
    "        y='anomaly',\n",
    "        labels={'full_date': 'Date', 'anomaly': 'Taux d\\'anomalies'},\n",
    "        title=\"Taux d'anomalies par jour\"\n",
    "    )\n",
    "    \n",
    "    return dbc.Container([\n",
    "        dbc.Row([\n",
    "            dbc.Col(html.H1(\"KPIs\", className='text-center my-4'), width=12)\n",
    "        ]),\n",
    "        \n",
    "        dbc.Row([\n",
    "            dbc.Col(create_metric_card(\"Taux d'Anomalies\", f\"{metrics['anomaly_rate']:.2%}\", \n",
    "                                      \"primary\", f\"Sur {len(X_test_result)} observations\", \n",
    "                                      metrics['anomaly_rate']*100), md=3),\n",
    "            dbc.Col(create_metric_card(\"Coût Estimé\", f\"{metrics['estimated_cost']:,.0f} DZD\", \n",
    "                                      \"warning\"), md=3),\n",
    "            dbc.Col(create_metric_card(\"BU la Plus à Risque\", metrics['top_risk_BU'], \n",
    "                                      \"info\", f\"Taux: {metrics['BU_anomaly_rate']:.2%}\"), md=3),\n",
    "            dbc.Col(create_metric_card(\"Dernière Anomalie\", metrics['last_anomaly_date'], \n",
    "                                      None, \"Détectée le\"), md=3)\n",
    "        ], className=\"mb-4\"),\n",
    "        \n",
    "        dbc.Row([\n",
    "            dbc.Col([\n",
    "                dbc.Card([\n",
    "                    dbc.CardHeader(\"Évolution Temporelle des Anomalies\"),\n",
    "                    dbc.CardBody([\n",
    "                        dcc.Graph(figure=fig_date)\n",
    "                    ])\n",
    "                ])\n",
    "            ], md=6),\n",
    "            dbc.Col([\n",
    "                html.Div([\n",
    "                    dbc.Label(\"Sélectionnez une BU :\"),\n",
    "                    dcc.Dropdown(\n",
    "                        id='bu-selector',\n",
    "                        options=[{'label': bu, 'value': bu} for bu in df['BU'].dropna().unique()],\n",
    "                        value=df['BU'].mode()[0],\n",
    "                        clearable=False\n",
    "                    )\n",
    "                ]),\n",
    "                dbc.Card([\n",
    "                    dbc.CardHeader(\"Répartition des anomalies par utilisateur\"),\n",
    "                    dbc.CardBody([\n",
    "                        dcc.Graph(id='dok-usr-pie')\n",
    "                    ])\n",
    "                ])\n",
    "            ], md=6)\n",
    "        ]),\n",
    "        \n",
    "        dcc.Interval(id='refresh-interval', interval=60*1000, n_intervals=0)\n",
    "    ], fluid=True)\n",
    "\n",
    "def create_metric_card(title, value, color, subtitle=None, progress_value=None):\n",
    "    card_body = [\n",
    "        html.H4(value, className=f\"card-title {'text-' + color if color else ''}\")\n",
    "    ]\n",
    "    \n",
    "    if subtitle:\n",
    "        card_body.append(html.Small(subtitle, className=\"text-muted\"))\n",
    "    \n",
    "    if progress_value is not None:\n",
    "        card_body.append(\n",
    "            dbc.Progress(\n",
    "                value=progress_value, \n",
    "                max=100, \n",
    "                color=color, \n",
    "                striped=True,\n",
    "                className=\"mt-2\"\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    return dbc.Card([\n",
    "        dbc.CardHeader(title),\n",
    "        dbc.CardBody(card_body)\n",
    "    ])\n",
    "\n",
    "# ==============================================\n",
    "# APP LAYOUT\n",
    "# ==============================================\n",
    "\n",
    "app.layout = html.Div([\n",
    "    dcc.Location(id='url', refresh=False),\n",
    "    create_navbar(),\n",
    "    html.Div(id='page-content')\n",
    "])\n",
    "\n",
    "# ==============================================\n",
    "# CALLBACKS\n",
    "# ==============================================\n",
    "\n",
    "@app.callback(\n",
    "    Output('page-content', 'children'),\n",
    "    [Input('url', 'pathname')]\n",
    ")\n",
    "def display_page(pathname):\n",
    "    if pathname == '/':\n",
    "        return create_home_layout()\n",
    "    elif pathname == '/anomaly-analysis':\n",
    "        return create_anomaly_analysis_layout()\n",
    "    elif pathname == '/frequent-values':\n",
    "        return create_frequent_values_layout()\n",
    "    else:\n",
    "        return create_home_layout()\n",
    "\n",
    "@app.callback(\n",
    "    Output('anomaly-segmentation-plot', 'figure'),\n",
    "    Input('segmentation-attribute', 'value'),\n",
    "    prevent_initial_call=True\n",
    ")\n",
    "def update_segmentation_plot(attribute):\n",
    "    anomalies_idx = X_test_result[X_test_result['anomaly'] == 1].index\n",
    "    anomalies_original = df.loc[anomalies_idx].copy()\n",
    "    \n",
    "    if attribute == 'full_date':\n",
    "        anomalies_original['mois'] = pd.to_datetime(anomalies_original[attribute]).dt.month_name()\n",
    "        segment_counts = anomalies_original['mois'].value_counts().reset_index()\n",
    "        fig = px.bar(segment_counts, x='mois', y='count', \n",
    "                     title=\"Anomalies par mois\",\n",
    "                     labels={'mois': 'Mois', 'count': \"Nombre d'anomalies\"})\n",
    "    else:\n",
    "        column_data = anomalies_original[attribute]\n",
    "        segment_counts = column_data.value_counts().reset_index()\n",
    "        \n",
    "        if len(segment_counts) > 20:\n",
    "            segment_counts = segment_counts.nlargest(20, 'count')\n",
    "\n",
    "        if pd.api.types.is_numeric_dtype(column_data):\n",
    "            fig = px.histogram(column_data, x=attribute,\n",
    "                             title=f\"Distribution des anomalies par {attribute}\",\n",
    "                             nbins=20)\n",
    "        else:\n",
    "            fig = px.bar(segment_counts, x=attribute, y='count',\n",
    "                        title=f\"Anomalies par {attribute}\",\n",
    "                        labels={attribute: attribute, 'count': \"Nombre d'anomalies\"})\n",
    "\n",
    "    fig.update_layout(\n",
    "        xaxis_title=attribute,\n",
    "        yaxis_title=\"Nombre d'anomalies\",\n",
    "        hovermode='x'\n",
    "    )\n",
    "    return fig\n",
    "\n",
    "@app.callback(\n",
    "    Output('feature-importance', 'figure'),\n",
    "    Input('feature-importance', 'id')\n",
    ")\n",
    "def update_feature_importance(_):\n",
    "    anomalies = X_test_result[X_test_result['anomaly'] == 1]\n",
    "    feature_scores = {}\n",
    "    \n",
    "    for col in selected_final:\n",
    "        if np.issubdtype(X_test[col].dtype, np.number):\n",
    "            median = X_train[col].median()\n",
    "            iqr = X_train[col].quantile(0.75) - X_train[col].quantile(0.25)\n",
    "            score = np.mean(np.abs(anomalies[col] - median) / (iqr + 1e-8))\n",
    "            feature_scores[col] = score\n",
    "    \n",
    "    sorted_features = sorted(feature_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    return px.bar(\n",
    "        x=[f[0] for f in sorted_features],\n",
    "        y=[f[1] for f in sorted_features],\n",
    "        labels={'x': 'Variable', 'y': 'Score d\\'importance'},\n",
    "        title=\"Contribution des Variables aux Anomalies\"\n",
    "    )\n",
    "\n",
    "@app.callback(\n",
    "    Output('anomaly-details', 'children'),\n",
    "    Input('anomaly-selector', 'value'),\n",
    "    prevent_initial_call=True\n",
    ")\n",
    "def update_anomaly_details(selected_index):\n",
    "    if selected_index is None:\n",
    "        return dbc.Alert(\"Sélectionnez une anomalie pour voir les détails\", color=\"info\")\n",
    "    \n",
    "    explanations = anomaly_explainer.explain_anomalies()\n",
    "    explanation = next((exp for exp in explanations if exp['index'] == selected_index), None)\n",
    "\n",
    "    if not explanation:\n",
    "        return dbc.Alert(\"Impossible d'expliquer cette anomalie\", color=\"warning\")\n",
    "    \n",
    "    suspicion_score = explanation['suspicion_score'] * 10\n",
    "    features = explanation['top_contributors']\n",
    "    \n",
    "    suspicion_gauge = dcc.Graph(\n",
    "        figure={\n",
    "            'data': [{\n",
    "                'type': 'indicator',\n",
    "                'mode': 'gauge+number',\n",
    "                'value': suspicion_score,\n",
    "                'title': {'text': \"Score de Suspicion\"},\n",
    "                'gauge': {\n",
    "                    'axis': {'range': [0, 10]},\n",
    "                    'steps': [\n",
    "                        {'range': [0, 4], 'color': \"lightgreen\"},\n",
    "                        {'range': [4, 7], 'color': \"orange\"},\n",
    "                        {'range': [7, 10], 'color': \"red\"}\n",
    "                    ]\n",
    "                }\n",
    "            }],\n",
    "            'layout': {'height': 200, 'margin': {'t': 0, 'b': 0}}\n",
    "        },\n",
    "        className='mb-4'\n",
    "    )\n",
    "\n",
    "    deviations = [explanation['deviation_values'].get(f, 0) for f in features]\n",
    "    radar_chart = dcc.Graph(\n",
    "        figure={\n",
    "            'data': [{\n",
    "                'type': 'scatterpolar',\n",
    "                'r': deviations + [deviations[0]] if deviations else [],\n",
    "                'theta': features + [features[0]] if features else [],\n",
    "                'fill': 'toself',\n",
    "                'name': 'Déviation'\n",
    "            }],\n",
    "            'layout': {\n",
    "                'polar': {'radialaxis': {'visible': True}},\n",
    "                'height': 300,\n",
    "                'margin': {'t': 30, 'b': 30}\n",
    "            }\n",
    "        },\n",
    "        className='mb-4'\n",
    "    )\n",
    "\n",
    "    var_cards = []\n",
    "    for feature in features:\n",
    "        true_value = explanation['real_values'].get(feature, \"N/A\")\n",
    "        deviation = explanation['deviation_values'].get(feature, 0)\n",
    "        bar_color = \"danger\" if deviation > 0 else \"info\"\n",
    "\n",
    "        var_cards.append(\n",
    "            dbc.Card([\n",
    "                dbc.CardHeader(f\"Variable : {feature}\"),\n",
    "                dbc.CardBody([\n",
    "                    html.H5(f\"{true_value}\", className=\"card-title\"),\n",
    "                    html.P(\"Écart par rapport à la moyenne locale :\"),\n",
    "                    dbc.Progress(\n",
    "                        value=min(abs(deviation) * 10, 10),\n",
    "                        max=10,\n",
    "                        color=bar_color,\n",
    "                        label=f\"{deviation:.2f}\",\n",
    "                        className=\"mb-2\"\n",
    "                    ),\n",
    "                    dbc.Badge(\n",
    "                        \"Au-dessus\" if deviation > 0 else \"En-dessous\",\n",
    "                        color=bar_color,\n",
    "                        className=\"me-1\"\n",
    "                    )\n",
    "                ])\n",
    "            ], className=\"mb-3\")\n",
    "        )\n",
    "\n",
    "    return html.Div([\n",
    "        dbc.Row([\n",
    "            dbc.Col(suspicion_gauge, width=6),\n",
    "            dbc.Col(radar_chart, width=6)\n",
    "        ]),\n",
    "        html.Hr(),\n",
    "        html.H4(\"Détails des variables\", className=\"mt-3\"),\n",
    "        dbc.Row([dbc.Col(card) for card in var_cards])\n",
    "    ])\n",
    "\n",
    "@app.callback(\n",
    "    Output('dok-usr-pie', 'figure'),\n",
    "    Input('bu-selector', 'value')\n",
    ")\n",
    "def update_pie_chart(selected_bu):\n",
    "    anomalies_with_BU = df.loc[X_test_result[X_test_result['anomaly'] == 1].index].copy()\n",
    "    filtered = anomalies_with_BU[anomalies_with_BU['BU'] == selected_bu]\n",
    "    return px.pie(\n",
    "        filtered,\n",
    "        names='DOK_SCN_USR',\n",
    "        title=f\"Anomalies par utilisateur pour la BU {selected_bu}\",\n",
    "        hole=0.4\n",
    "    )\n",
    "\n",
    "@app.callback(\n",
    "    Output('comparative-scatter', 'figure'),\n",
    "    [Input('scatter-x', 'value'),\n",
    "     Input('scatter-y', 'value')]\n",
    ")\n",
    "def update_scatter(x_col, y_col):\n",
    "    return px.scatter(\n",
    "        X_test_result,\n",
    "        x=x_col,\n",
    "        y=y_col,\n",
    "        color='anomaly',\n",
    "        marginal_x=\"box\",\n",
    "        marginal_y=\"violin\"\n",
    "    )\n",
    "\n",
    "# ==============================================\n",
    "# RUN APP\n",
    "# ==============================================\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Ouvre automatiquement dans un navigateur\n",
    "    Timer(1, lambda: webbrowser.open_new(\"http://127.0.0.1:8050/\")).start()\n",
    "    app.run(debug=True, use_reloader=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
